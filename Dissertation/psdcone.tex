\chapter{Positive semidefinite cone of an association scheme}\label{psdcone}
Consider the following classic unsolved problem in discrete geometry (\cite{Haantjes1948},\cite{vanLint1966},\cite{Lemmens1973}): Given a fixed positive integer $n$, what is the maximum number of lines through the origin one may find in $\mathbb{R}^n$ such that the angle between any pair of distinct lines is $\theta$. Over the past 70 years, researchers in both math and physics have developed the theory of these ``equiangular lines" (also ``equiangular tight frames"), finding upper bounds on the number of lines in any given dimension coming from tools such as linear programming \cite{Delsarte1975}, number theory \cite{Lemmens1973}, and more recently semidefinite programming \cite{Barg2014}. A related problem asks the question: How many orthonormal basis may we find in $\mathbb{R}^n$ such that the angle between vectors in distinct bases is fixed, called ``mutually unbiased bases" (see \cite{Delsarte1975}, \cite{Calderbank1997},\cite{Boykin2005}). While the complex analogue of both of these questions have had great interest in Quantum computing (\cite{Appleby2005},\cite{Grassl2008},\cite{Ivanovic1981},\cite{Wootters1989}), we restrict ourselves to the real cases in this document as the Bose-Mesner algebra of any symmetric association scheme is real.

Both of the problems mentioned above are restricted versions of the more general question of finding spherical $t$-distance sets: sets of unit vectors in a fixed dimension with only $t$ distinct inner products arising between pairs of vectors. In each case we may recast the problem to looking for large positive semidefinite matrices with a low rank, constant diagonal, and few distinct entries off the diagonal. More precisely, let $G$ be a $n\times n$ positive semidefinite matrix with rank $r$. Then there exists a $r\times n$ matrix $U$ such that $G = U^TU$; that is $G$ is the Gram matrix of the columns of $U$. If $G$ has a constant diagonal, then we may scale the columns of $U$ so that each column is a unit vector without increasing the number of distinct inner products. The columns of $U$ therefore give a spherical $t$-distance set in $\mathbb{R}^r$ where $t$ is the number of unique entries off the diagonal of $G$. Now recall that a $d$-class association scheme results in a Bose-Mesner algebra with $d+1$ basis idempotents. These idempotents serve as the basis of the cone of positive semidefinite matrices inside our Bose-Mesner algebra. However noting that every matrix in our Bose-Mesner algebra has a constant diagonal and at most $d$ entries off the main diagonal, we often find Gram matrices for large spherical $t$-distance sets within this algebra. Given any association scheme, finding such a matrix not only guarantees the existence of the $t$-distance set but allows us to compute the vectors explicitly. Conversely, any restrictions we find on the existence of such $t$-distance sets allows us to add feasibility conditions on the parameters of association schemes. For instance, Delsarte et al.\ \cite{Delsarte1975} found bounds on the size of any $t$-distance set based solely on the dimension of the ambient space and the inner products allowed between vectors. Such an observation allows us to rule out certain parameter sets if the rank of any matrix in the PSD cone falls too low compared to the number and values of the distinct entries off the diagonal. In a later paper \cite{Delsarte1977}, the same authors proved that a $s$-distance set is a spherical $t$-design if and only if each of the first $t$ Gegenbauer polynomials, summed over the inner products $\left<x,x'\right>$ ($x,x'\in X$) is zero. Further, they showed that if a $t$-design has fewer than $\frac{t+1}{2}$ distinct inner products, then it must correspond to the point set of an association scheme. Even further, Bannai and Bannai \cite{Bannai2008} showed that whenever the number of distinct inner products is within one of this bound, the $t$-design still admits an association scheme as long as the set of vectors is antipodal. This close relation between ``near-tight" $t$-designs and association schemes hints at the types of vector systems we should expect to find within our Bose-Mesner algebra. For instance, Suda \cite{Suda2011} used these results to characterize when the first idempotent of a $Q$-polynomial ordering results in a spherical $t$-design. A central tool in many of these results is a family of single-variable polynomials known as the Gegenbauer polynomials. A key result of Sch\"{o}nberg \cite{Schoenberg1942} concerning this family tells us that each Gegenbauer polynomial, when applied to a Gram matrix elementwise, results in a positive semidefinite matrix.
	
In this chapter we will examine the cone of positive semidefinite matrices within our Bose-Mesner algebras. We first display how one may build large spherical $t$-distance sets by taking non-negative linear combinations of the idempotents. Using this, we will build examples of equiangular lines meeting the maximum possible number of lines in given dimensions. We will then introduce the Gegenbauer polynomials as well as Sch\"{o}nberg's theorem. Using this theorem we will derive new constraints on the Krein parameters of any association scheme. We further examine these restrictions in the case of $Q$-polynomial association schemes where we give seven feasibility conditions which are not implied by the previously mentioned feasibility conditions; we believe these results are new. These results will be applied directly to the case of $4$-class $Q$-bipartite association schemes in Chapter \ref{4classbip}. Below we list the main theorems in this chapter.

In both Theorem \ref{schoen-as} and the final line of Theorem \ref{degreebound}, $Q_k^m(t)$ denotes the Gegenbauer polynomial of degree $k$ in dimension $m$.
\begin{restatable*}{lem}{buildingequi}\label{equilines}
	Let $(X,\cR)$ be given with second eigenmatrix $Q$. Define $Q^\prime$ to be the submatrix of $Q$ given by deleting row $0$. If there exists a non-negative solution to $Q^\prime x = y$ where each entry in $y$ is one of $\pm1$, then $\BMA$ contains the Gram matrix of $\vert X\vert$ equiangular lines in dimension $\sum_{x_j\neq 0} Q_{0j}$ with inner products $\pm\left(\sum x_jQ_{0j}\right)^{-1}$.
\end{restatable*}
\begin{restatable*}{thm}{schAS}\label{schoen-as}
	Let $(X,\mathcal{R})$ be an association scheme with minimal idempotents $E_0,\dots,E_d$ and matrices of Krein parameters $\displaystyle{L_0^*,\dots,L_d^*}$. For $0\leq i\leq d$, define $m_i:=\text{rank}\left(E_i\right)$. Then for any choice of $\ell>0$, there exist non-negative constants $\theta_{\ell j}$ for $0\leq j\leq d$ such that
	\begin{equation}\label{ELGeg}
	Q_\ell^{m_i}\circ\left(\frac{\vert X\vert}{m_i}E_i\right) = \sum_j \theta_{\ell j} E_j;\qquad	Q_\ell^{m_i}\left(\frac{1}{m_i}L_i^*\right) = \frac{1}{\vert X\vert}\sum_j \theta_{\ell j} L_j^*.
	\end{equation}
	The eigenvalues of $Q_\ell^{m_i}\circ\left(\frac{\vert X\vert}{m_i}E_i\right)$ are $\theta_{\ell 0},\dots,\theta_{\ell 1}$ where $\theta_{\ell j}$ is nonzero only if $E_j$ is contained in the Schur subalgebra generated by $E_i$.
\end{restatable*}

\begin{restatable*}{thm}{degbnd}\label{degreebound}
	Suppose we have a feasible parameter set for an association scheme with first and second eigenmatrices $P$ and $Q$. For $\ell>0$ and $0\leq i\leq d$ define $\mu_\ell = \frac{\ell-1}{\ell+Q_{0i}-3}$ and $\lambda_j = \nicefrac{Q_{ji}}{Q_{0i}}$. Let $\ell^*$ be the smallest integer such that
	\[\sum_{j=1}^d \left(\prod_{\ell=2}^{\ell^*+1}\gamma_{\ell,j}\right)P_{0j}\left(1+\lambda_j^2\right)\leq\frac{1}{\vert X\vert}\]
	where $\gamma_{l,j}$ is $\lambda_j^2$ if $(1+\mu_\ell)^2\lambda_j^2\geq 4\mu_\ell$ and $\mu_\ell$ otherwise. Then for $\ell\geq \ell^*$, the requirements derived from $Q_\ell^{m_i}\circ\left(\frac{\vert X\vert}{m_i}E_i\right)\succeq 0$ are implied by known feasibility conditions.
\end{restatable*}
\begin{restatable*}{thm}{cometricbounds}\label{cometricbnds}
	Suppose we have a feasible parameter set for a cometric association scheme with Krein array $\left\{m,b^*_1,\dots,b^*_{d-1};1,c_2^*\dots,c^*_{d}\right\}$ where $m>2$. Define $b_{j-1}^* = c_j^*=a_j^*=0$ for $j>d$. Then the scheme is realizable only if
	\begin{enumerate}[label=(\roman*)]
		\item $\left(a_1^*\right)^2 + b_1^*c_2^* \geq\frac{2m(m-1)}{m+2},$
		\item $\left(a_1^*\right)^2+2a_1^*a_2^*+c_2q^2_{22}\geq \frac{4m(m-2)}{m+4},$
		\item $\frac{6m(m-1)(m-4)}{(m+4)(m+6)}+\frac{\left(3a_1^*\left(a_1^*+a_2^*\right)+c_2q_{22}^2\right)b_1^*c_2^*+\left(a_1^*\right)^4}{m}\geq \frac{(7m-18)\left(\left(a_1^*\right)^2+b_1^*c_2^*\right)}{m+6},$
		\item $\sum_{i=1}^3\left(b_i^*c_{i+1}^* + a_i^*\sum_{j=i}^3 a_j^*\right)\leq \frac{3(3m-2)}{m+6}.$
		\item $\frac{16m(m-1)}{(m+4)(m+8)} + \frac{\left(a_1^*\right)^4 + \left(3a_1^*\left(a_1^*+a_2^*\right)+c_2^*q_{22}^2\right)b_1^*c_2^*}{(m-2)m}\geq \frac{12\left(\left(a_1^*\right)^2+b_1^*c_2^*\right)}{m+8},$
	\end{enumerate}
	Additionally, if $a_1^*>0$ then,
	\begin{enumerate}[label=(\roman*)]
		\addtocounter{enumi}{5}
		\item $\left(a_1^*\right)^2 + b_1^*c_2^*\left(2 + \frac{a_2^*}{a_1^*}\right)\geq \frac{4m(2m-3)}{m+6},$
		\item $\left(a_1^*\right)^2+2a_1^*a_2^*-\left(a_2^*\right)^2+2c_2^*q_{22}^2+\frac{b_2^*c_3^*\left(a_3^*-a_1^*\right)-ma_2^*}{a_1^*+a_2^*}\geq\frac{6m(m-4)}{m+6}.$
	\end{enumerate}
\end{restatable*}


\section{Equiangular lines in $\BMA$}\label{equilines}
Let $(X,\cR)$ be an association scheme with basis relations $A_0,\dots,A_d$ and orthogonal idempotents $E_0,\dots,E_d$. Since each $E_i$ is an idempotent matrix, it has spectrum $\left\{0,1\right\}$ and thus is positive semidefinite, denoted $E_i\succeq 0$. Further, let 
\begin{equation}G = \sum_i\alpha_i E_i.\label{lincomb}\end{equation}
Then we have $\text{spec}\left(G\right) = \left\{\alpha_0,\dots,\alpha_d\right\}$. Therefore $G\succeq 0$ if and only if $\alpha_i\geq 0$ for all $0\leq i\leq d$. Thus the \emph{positive semidefinite cone} of $(X,\cR)$ is the set of non-negative linear combinations of the idempotents $E_0,\dots,E_d$. Further, equation \eqref{lincomb} gives us that \begin{equation}\text{rank}\left(G\right) = \sum_{\alpha_i\neq 0} m_i.\label{rank}\end{equation}
Finally, since $G\in\BMA$ we must have $G = \sum_i \beta_i A_i$ and thus there are at most $d$ unique values off the main diagonal, making $\frac{1}{\beta_0}G$ the Gram matrix of a spherical $t$ distance set where $t\leq d$. In Chapter $\ref{3class}$ we examine one type of cometric association scheme where the first idempotent, $E_1$, gives an interesting 3-distance set where, in the optimal case, the number of vectors scales as $\frac{1}{2}v^2$ for dimension $v$. In this same case we show that adding another idempotent, namely $E_0$, allows us to build large sets of real mutually unbiased bases by choosing $\alpha_0$ and $\alpha_1$ carefully so that the non-zero entries off the diagonal of $G$ have a constant modulus. Before moving to two examples coming from $3$-class primitive cometric association schemes, we note the following bound on the maximum number of equiangular lines in a given dimension known as the relative bound.
\begin{thm}[\cite{vanLint1966}]\label{relbound}
	Let $v_\alpha(n)$ be the maximum number of equiangular lines with inner products $\pm\alpha$ in $\mathbb{R}^n$. If $n<\alpha^{-2}$ then
	\[v_\alpha(n)\leq\frac{r(1-\alpha^2)}{1-r\alpha^2}.\]
\end{thm}
In this section, we refer a system of lines as \emph{optimal} if it achieves the relative bound for the given dimension and innerproducts and \emph{near optimal} if it is within one line of being optimal. We now examine two 3-class primitive association schemes to illustrate how we may build equiangular lines from these schemes. The first comes from the Halved 7-cube while the second corresponds to the Dual Polar space $B_3(2)$.
\begin{example}
	Consider the 3-class primitive association scheme given by the Halved 7-cube \cite{Brouwer1989}. This scheme is both metric and cometric with the following eigenmatrices
	\[P = \left[\begin{array}{rrrr}
	1& 21& 35& 7\\
	1& 9& -5& -5\\
	1& 1& -5& 3\\
	1& -3& 3& -1\\
	\end{array}\right],\qquad  Q= \left[\begin{array}{rrrr}
	1& 7& 21& 35\\
	1& 3& 1& -5\\
	1& -1& -3& 3\\
	1& -5& 9& -5\\
	\end{array}\right].\]
	Recall that $E_j = \frac{1}{\vert X\vert}\sum_{i}Q_{ji}A_i$ and consider
	\[G = 16\left(E_1 + E_2\right).\]
	We may then use the entries of $Q$ to replace each idempotent with the corresponding sum of adjacency matrices giving 
	\[G = 7A_0 + A_1 -A_2+A_3.\]
	Then $\frac{1}{7}G$ is the Gram matrix of $64$ lines in dimension $m_1+m_2 = 28$ with inner products $\pm\frac{1}{7}$. Using the relative bound, we find that this system is optimal.
\end{example}
\begin{example}
	Consider the 3-class primitive cometric (and metric) association scheme known as the dual polar space $B_3(2)$. The first and second eigenmatrices are
	\[P = \left[\begin{array}{rrrr}
	1& 14& 56& 64\\
	1& 5& -2& -8\\
	1& -1& -4& 4\\
	1& -7& 14& -8\\
	\end{array}\right],\qquad  Q= \left[\begin{array}{rrrr}
	1& 35& 84& 15\\
	1& \nicefrac{25}{2}& -6& -\nicefrac{15}{2}\\
	1& \nicefrac{5}{4}& -6& \nicefrac{15}{4}\\
	1& -\nicefrac{35}{8}& \nicefrac{21}{4}& -\nicefrac{15}{8}\\
	\end{array}\right].\]
	Consider the matrix
	\[G = 15E_0+24E_1 + 24E_2 = 9A_0 + A_1 +A_2-A_3.\]
	Similar to before, $\frac{1}{9}G$ is the Gram matrix of $135$ lines in dimension $m_0+m_1+m_2 = 51$ with inner products $\pm\frac{1}{9}$. Here, the relative bound tells us that optimal number of lines in dimension 51 with these inner products is 136, thus this construction is near optimal.
\end{example}
\begin{comment}
\begin{example}
	Consider the 3-class primitive cometric association scheme coming from the Dual Kasami codes \cite{deCaen1999}. The first and second eigenmatrices are:
	\[P = \left[\begin{array}{cccc}
	1& 310& 527& 186\\
	1& 70& -17& -17\\
	1& 6& -17& 15\\
	1& -10& 15& -17\\
	\end{array}\right]\qquad  Q= \left[\begin{array}{cccc}
	1& 31& 465& 527\\
	1& 7& 9& -17\\
	1& -1& -15& 15\\
	1& -9& 25& -17\\
	\end{array}\right].\]
	Consider the matrix
	\[G = \frac{1024}{496}\left(E_1 + E_2\right) = A_0 + \frac{1}{31}A_1 -\frac{1}{31}A_2+\frac{1}{31}A_3.\]
	Similar to before, $G$ is the Gram matrix of $1024$ lines in dimension $m_1+m_2 = 496$ with inner product $\frac{1}{31}$. Using the relative bound, we find that this is the optimal number of equiangular lines possible in dimension $496$ with an inner product of $\frac{1}{31}$.
\end{example}
\end{comment}
%In both of the examples above, we find linear combinations of the idempotents where the idempotent with largest multiplicity has coefficient 0. While we may allow ourselves to include this idempotent, doing so often results in line-sets which are far from optimal. 
We now consider the construction in general.

\buildingequi
\begin{comment}
\begin{lem}\label{equilines}
Let $(X,\cR)$ be a $d$-class association scheme with second eigenmatrix $Q$ and idempotents $E_0,E_1,\dots,E_d$. Let $Q^\prime$ be the $d\times (d+1)$ submatrix of $Q$ given by deleting row $0$. Let $x$ be a solution of $Q^\prime x = y$ (if one exists) where each entry in $y$ is one of $\pm1$. If $x$ contains no negative entries then $\BMA$ contains the Gram matrix of $\vert X\vert$ equiangular lines in dimension $\sum_{x_j\neq 0} Q_{0j}$ with inner products $\pm\left(\sum x_jQ_{0j}\right)^{-1}$.
\end{lem}
\end{comment}
\begin{proof}
	Noting that $Q^\prime x = y$ we have the $d$ equations
	\[Q_{i1}x_1 + \dots + Q_{id}x_d = c_i\]
	for $1\leq i\leq d$ where each $c_i$ is either $1$ or $-1$.	Then
	\[G = \sum_{j\neq i}x_jE_j = \frac{1}{\vert X\vert}\sum_{i=0}^{d}\left(\sum_{j=0}^dQ_{ij}A_i\right) = \frac{1}{\vert X\vert}\sum_{j=0}^d x_jm_jA_0 + \frac{1}{\vert X\vert}\sum_{i=1}^d c_iA_i.\]
	Since $\vert c_i\vert = 1$ for each $1\leq i\leq d$, each off diagonal entry of $G$ has the same absolute value. Thus we may scale $G$ by its diagonal entry to obtain the Gram matrix of a set of equiangular unit vectors. The rank of $G$ is the sum of the ranks of each $E_j$ with $x_j\neq 0$ while the inner product between distinct unit vectors is $\pm\left(\sum x_jQ_{0j}\right)^{-1}$.
\end{proof}
\begin{table}[H]
We finish this section by applying Lemma \ref{equilines} to the tables in \cite{Willifordtable}.
	\begin{center}
	Optimal constructions\\
\begin{tabular}{l|c|c|ccl|c|c|c}
	Label & $\vert X\vert$ & $n$ & $\nicefrac{1}{\alpha}$&&Label & $\vert X\vert$ & $n$ & $\nicefrac{1}{\alpha}$ \\\cline{1-4}\cline{6-9}
$\left<64,7\right>^*$ & 64 & 28 & 7 & \qquad &$\left<1200,55\right>$ & 1200 & 110 & 11	\\ 
$\left<64,9\right>^*$ & 64 & 36 & 9 & \qquad	&$\left<1200,109a\right>$ & 1200 & 110 & 11\\
$\left<64,21\right>^*$ & 64 & 28 & 7 & \qquad &$\left<1344,79\right>$ & 1344 & 238 & 17 \\
$\left<120,9\right>^*$ & 120 & 35 & 7 & \qquad &$\left<1456,90a\right>$ & 1456 & 195 & 15 \\
$\left<120,14\right>^*$ & 120 & 35 & 7 &	\qquad &$\left<1456,97\right>$ & 1456 & 195 & 15 \\
$\left<120,17a\right>^*$ & 120 & 35 & 7 &\qquad  &$\left<1520,49\right>$ & 1520 & 589 & 31 \\
$\left<280,27a\right>$ & 280 & 63 & 9 &\qquad   &$\left<1520,56\right>$ & 1520 & 589 & 31 \\
$\left<324,19a\right>$ & 324 & 171 & 19 &\qquad  &$\left<1596,55\right>$ & 1596 & 551 & 29\\
$\left<344,42\right>$ & 344 & 43 & 7 & \qquad &$\left<2016,62a\right>$ & 2016 & 651 & 31 \\
$\left<460,51\right>$ & 460 & 69 & 9 & \qquad &$\left<2016,65\right>$ & 2016 & 651 & 31\\
$\left<540,44\right>$ & 540 & 99 & 11 & \qquad &$\left<2160,119\right>$ & 2160 & 255 & 17\\
$\left<540,49\right>$ & 540 & 99 & 11 & \qquad &$\left<2160,119a\right>$ & 2160 & 255 & 17 \\
$\left<936,51\right>$ & 936 & 221 & 17 & \qquad &$\left<2160,119b\right>$ & 2160 & 255 & 17 \\
$\left<936,51a\right>$ & 936 & 221 & 17 & \qquad &$\left<2500,51\right>$ & 2500 & 1225 & 49\\
$\left<1024,31\right>^*$ & 1024 & 496 & 31 & \qquad &$\left<2500,51a\right>$ & 2500 & 1275 & 51 \\
$\left<1024,33\right>$ & 1024 & 528 & 33 & \qquad &$\left<2500,75\right>$ & 2500 & 1275 & 51 \\
$\left<1024,66\right>^*$ & 1024 & 528 & 33 & \qquad 
\end{tabular}\\\vspace{5mm}
Near Optimal constructions\\
\begin{tabular}{l|c|c|ccl|c|c|c}
	Label & $\vert X\vert$ & $n$ &  $\nicefrac{1}{\alpha}$&&Label & $\vert X\vert$ & $n$ & $\nicefrac{1}{\alpha}$\\\cline{1-4}\cline{6-9}
$\left<35,6\right>^*$ & 35 & 21 & 7 & \qquad &$\left<729,56\right>$ & 729 & 337 & 25\\
$\left<135,35\right>^*$ & 135 & 51 & 9 & \qquad &$\left<923,70\right>$ & 923 & 143 & 13 \\
$\left<279,30\right>$ & 279 & 63 & 9 & \qquad &$\left<1035,68\right>$ & 1035 & 185 & 15 \\
$\left<319,28\right>$ & 319 & 88 & 11 & \qquad &$\left<1349,70\right>$ & 1349 & 285 & 19 \\
$\left<377,28\right>$ & 377 & 117 & 13 & \qquad &$\left<1975,78\right>$ & 1975 & 475 & 25 \\
$\left<527,30\right>$ & 527 & 187 & 17 & \qquad &$\left<2159,126\right>$ & 2159 & 255 & 17 \\
$\left<527,30a\right>$ & 527 & 187 & 17 & \qquad &$\left<2759,88\right>$ & 2759 & 713 & 31 \\
\end{tabular}
\caption[Optimal and near-optimal constructions for equiangular lines using 3-class primitive cometric association schemes]{In these tables we give the sets of equiangular lines which may be built from the given 3-class primitive cometric scheme. Each parameter set is listed in \cite{Willifordtable} using the label in the far left column. For each set we list the number of lines $\vert X\vert$, dimension $n$, and the inverse of the inner product $\frac{1}{\alpha}$. The labels with stars correspond to parameter sets known to be realizable.}\label{optimalconst}
\end{center}
\end{table}
\begin{thm}
	For each near-optimal case listed in Table \ref{optimalconst} except for $\left<729,56\right>$, if the parameter set is realizable, we may extend the set of vectors by one to make it an optimal set.
\end{thm}
\begin{proof}
	In each case, $G = c_0 E_0 + \sum_{j=1}^{d}c_jE_j$ for orthogonal idempotents $E_0,\dots,E_d$ and $E_0 = \frac{1}{\vert X\vert}J$. Therefore $G\mathbbm{1} = c_0\mathbbm{1}$ and we must have $\text{rank}(\left[\begin{array}{c|c}
	G & c_0\mathbbm{1}
	\end{array}\right]) = \text{rank}\left(G\right)$ since the last column is the sum of all previous columns. Similarly, we may augment our new matrix with an extra row by adding all previous rows together giving
	\[G' = \left[\begin{array}{c|c}
	G & c_0\mathbbm{1}\\\hline
	c_0\mathbbm{1} & \vert X\vert c_0
	\end{array}\right]\]
	still with $\text{rank}(G') = \text{rank}(G)$. Finally, we may scale the last row and column each by $\sqrt{\vert X\vert c_0}$ without changing the rank, since this equates to multiplying a single vector in the set by a scaler. The resulting matrix is as follows
	\[H = \left[\begin{array}{c|c}
	G & \sqrt{\frac{c_0}{\vert X\vert}}\mathbbm{1}\\\hline
	\sqrt{\frac{c_0}{\vert X\vert}}\mathbbm{1}^T & 1
	\end{array}\right].\]
	If $\sqrt{\frac{c_0}{\vert X\vert}} = \alpha$, then this corresponds to the Gram matrix of a set of $\vert X\vert+1$ equiangular vectors in the same dimension. Thus we must check that the coefficient of $E_0$ is $\vert X\vert\alpha^2$. We verify that this hold for every case except $\left<729,56\right>$. Note that this exceptional case is the only listed case where the relative bound is not an integer. That is, $\frac{337(1-\frac{1}{25^2})}{1-\frac{337}{25^2}} = \frac{4381}{6}\approx 730.167$. Since the bound concerns the maximum cardinality of a set, this results in an upper bound of 730. However even a set with 730 vectors in dimension 25 would not make this bound sharp--this is likely why this case fails.  
\end{proof}
\section{Gegenbauer Polynomials}\label{gegdef}
In all that follows let $m$ be a fixed positive integer and define $\scR:=\bbR[x_1,\dots,x_m]$. A \emph{monomial} is defined as a (possibly empty) product of variables $x_1,\dots,x_m$ and given a monomial $t =\prod_{i=1}^{m}x_i^{d_i}$ ($d_i\in \bbZ^+$), the \emph{degree} of $t$ is defined as $\text{deg}(t) = \sum_i d_i$. A polynomial $f\in\scR$ may be represented uniquely as a (finite) linear combination of distinct monomials $f =\sum_i\alpha_it_i$ and $\text{deg}(f) = \max\left\{\text{deg}(t_i)\right\}$. For each variable $x_j$, we define the \emph{derivative with respect to $x_j$} of a monomial as $\frac{\partial}{\partial x_j}t = \frac{d_j}{x_j}t$ and extend the definition linearly for any polynomial in $\scR$. For $f\in \scR$, $f$ is \emph{homogeneous} if there exists some constant $d\in\bbZ^+$ such that $\text{deg}(t)=d$ for every monomial $t$ in $f$. Further, $f$ is \emph{harmonic} if $\Delta f = \sum_i \left(\frac{\partial}{\partial x_i}\circ\frac{\partial}{\partial x_i}\right)\left(f\right) = 0$. For $f\in\scR$ the principal ideal generated by $f$ $(f) = \left\{gf:g\in\scR\right\}$. We denote the cosets of this ideal by $[g]_f = \left\{h\in\scR: g-h\in(f)\right\}$ where we suppress the subscript if it is clear from the context. The quotient ring $\nicefrac{\scR}{(f)}$ is, of course, the set of equivalence classes $\left\{[g]_f:g\in\scR\right\}$ with the obvious operations. Let $S^{m-1}\subset \bbR^m$ be the $m-1$ dimensional sphere; we define the set of polynomials on the sphere as
\[\text{Pol}(S^{m-1}):= \nicefrac{\scR}{\left(1-\sum_ix_i^2\right)}.\]
We say a polynomial $h\in\scR$ is \emph{harmonic on the sphere} if there exists a harmonic polynomial $g\in[h]$; we similarly define \emph{homogeneous on the sphere}. Finally, we say a polynomial $f\in\scR$ is \emph{zonal} if there exists a vector $a\in \bbR^m$ and a single-variable polynomial $p(t)\in\bbR[t]$ such that $f(x) = p(\left<a,x\right>)$ for all $x\in S^{m-1}$. Note that since $g\in \left(1-\sum_ix_i^2\right)$ implies $g(x) = 0$ for all $x\in S^{m-1}$, this requirement is independent of the representative chosen from the equivalence class.\par
We now introduce a set of orthogonal polynomials arising from the context of spherical harmonics. The Gegenbauer polynomials in dimension $m$ are defined using the three-term recurrence:
\begin{equation}\label{recurrence}
Q_\ell^m(t) = \frac{(2\ell+m-4)tQ^m_{\ell-1}(t) - (\ell-1)Q^m_{\ell-2}(t)}{\ell+m-3} \qquad \ell\geq 2,
\end{equation}
\begin{equation*}
Q^m_0(t) = 1\qquad Q^m_1(t) = t.
\end{equation*}
Note that $Q^m_\ell(1) = 1$ for all $k\geq 0$. We will suppress the superscript $m$ if it is clear in the context. Below we list the first six Gegenbauer polynomials and plot $Q_1(t)-Q_5(t)$ along with their roots.
\[
Q_0(t)=1,\qquad
Q_1(t)=t,\qquad
Q_2(t)=\frac{mt^2 - 1}{m-1},\qquad
Q_3(t)=\frac{(m+2)t^3 - 3t}{m-1},\qquad\]\[
Q_4(t)=\frac{(m+4)(m+2)t^4 - 6(m+2)t^2+3}{m^2-1},\]\[
Q_5(t)=\frac{(m+6)(m+4)t^5-10(m+4)t^3+15t}{m^2-1}.\]
\begin{figure}[!h]
	\begin{center}
		\includegraphics[scale=.35]{gegenbauer_polynomials.PNG}
		\caption[Gegenbauer polynomials]{Gegenbauer polynomials with degree 1 through degree 5 with $m=10$.}\label{gegpic}
	\end{center}
\end{figure}
\begin{figure}[!h]
	\begin{center}
		\includegraphics[scale=.35]{roots.PNG}
		\caption[Roots of Gegenbauer polynomials]{Roots of the five Gegenbauer polynomials with degrees $1$ to $5$.}\label{rootpic}
	\end{center}
\end{figure}
\begin{thm}\label{gegprop}
	For each $m,\ell\in\bbZ^+$ and $a\in\bbR^m$, the Gegenbauer polynomial $Q_\ell^m\left(\left<a,x\right>\right)$ is zonal and both homogeneous and harmonic on the sphere.
\end{thm}
\begin{proof}
	The zonal condition is satisfied by construction. The other two conditions follow from considering $F^m_\ell(x)\in\left[Q_\ell^m(\left<a,x\right>)\right]$ where 
	\[F_\ell^m(x)= \left<x,x\right>^{\lfloor\frac{\ell+1}{2}\rfloor}Q_\ell^m\left(\frac{\left<a,x\right>}{\left<x,x\right>}\right).\]
\end{proof}
We note that, up to scaling and rotation of the sphere, $F_\ell^m(x)$ as defined above is the unique degree $\ell$ polynomial with all three of these properties. These polynomials have played an important role in understanding spherical $t$-distance sets as well as $t$-designs (\cite{Delsarte1977},\cite{Suda2011}). Many of these results come from considering a finite set $X\subset\mathbb{S}^m$ and a basis $q_1,\dots, q_M$ of the harmonic polynomial functions on the sphere with fixed degree $k$. We then map $X$ to $\mathbb{R}^M$ by evaluating each point at every basis polynomial. Fixing two points, $\zeta,\xi\in X$, we then use Theorem \ref{gegprop} to show that $\left<\phi(\zeta),\phi(\xi)\right> = c_kQ^m_k\left(\left<\zeta,\phi\right>\right)$ where the constant $c_k$ does not depend on the points choosen. It should not be surprising that these polynomials were of interest before their use in combinatorics \cite{Delsarte1977}. In fact 
35 years earlier, Sch\"{o}nberg characterized positive definite functions on the sphere using these same polynomials.
\section{Sch\"{o}nberg's Theorem}
Let $m$ be a fixed positive integer and let $X\subset S^{m-1}$ be a finite set of unit vectors. Let $G_X$ denote the Gram matrix of $X$, then $G_X$ is positive semidefinite ($G_X\succeq 0$). A function $f:[-1,1]\rightarrow\mathbb{R}$ is \textit{positive definite} if, for every such finite subset $X$, $f$ applied elementwise to $G_X$ results in a positive semidefinite matrix, i.e.\ $f\circ(G_X)\succeq 0$. Here we present a Sch\"{o}nberg's Theorem \cite{Schoenberg1942} as it applies to polynomials.
\begin{thm}[Sch\"{o}nberg \cite{Schoenberg1942}]\label{schoenthm}
	Fix $m\in\mathbb{Z}^+$. A polynomial $f:[-1,1]\rightarrow\mathbb{R}$ with degree $d$ is positive definite on $S^{m-1}$ if and only if $f(t) = \sum_{\ell=0}^d c_\ell Q_\ell^m(t)$ for non-negative constants $c_\ell$.\qed
\end{thm}
In particular, this implies that $Q_\ell^m(t)$ is a positive definite function for any choice of $m$ and $\ell$. This leads to the following theorem:
\schAS
\begin{proof}
	Since $\BMA =\text{span}\left\{E_0,\dots,E_d\right\}$ is closed under entrywise products, we must have $Q_k^{m_i}\circ\left(\frac{\vert X\vert}{m_i}E_i\right)\in \BMA$ and we may write $Q_k^{m_i}\circ\left(\frac{\vert X\vert}{m_i}E_i\right) = \sum_j \theta_{kj} E_j$ where each $\theta_{kj}$ is the eigenvalue of $Q_k^{m_i}\circ\left(\frac{\vert X\vert}{m_i}E_i\right)$ in the eigenspace $V_j$. Now recall the algebra isomorphism $\phi^*:\BMA\rightarrow\bbL$ mapping entrywise products to standard matrix products for which $\phi^*\left(E_j\right)=\frac{1}{\vert X\vert}L_j^*$. Applying $\phi^*$ to both sides of the equation on the left in \eqref{ELGeg} results in the equation on the right in \eqref{ELGeg}. Finally, since $E_i$ is an idempotent matrix with constant main diagonal entries given by $\frac{1}{\vert X\vert}Q_{0i} = \frac{m_i}{\vert X\vert}$, we know that $\frac{\vert X\vert}{m_i}E_i$ is the Gram matrix of a set of points in $S^{m_i-1}$. Therefore, Theorem~\ref{schoenthm} tells us that $Q_k^{m_i}\circ\left(\frac{\vert X\vert}{m_i}E_i\right)$ must be positive semidefinite.
\end{proof}
\subsection{Proof of Theorem \ref{degreebound}}\label{proof}
Given a feasible parameter set with $i^\text{th}$ matrix of Krein parameters $L_i^*$, we seek to derive a bound on the highest degree Gegenbauer $Q_\ell(t) = Q_\ell^{m_i}(t)$ for which $Q_\ell\left(\frac{1}{m_i}L_i^*\right)$ may contain negative entries. We will do this by first simplifying equation \eqref{ELGeg} into a vector equation and deriving a three term vector recurrence of non-negative vectors. We then transform our vector space in two ways, first using an invertible transformation which changes our transition matrix from $\frac{1}{m}L_i^*$ to one which is orthogonally diagonalizable. We then map our vector space to one with twice the dimension where our three-term recurrence may be represented as a linear recurrence. Using this linear recurrence we express our initial vector as a sum of steady state vectors and transient vectors in order to find a bound on how quickly the transient vectors must decrease in norm. In all that follows suppose we have a feasible parameter set with first and second eigenmatrix $P$ and $Q$. For fixed $0\leq i\leq d$, let $L_i^*$ be the $i^\text{th}$ matrix of Krein parameters. Let $\ell\geq0$ be an integer and assume $m_i:=q_{0i}^i>2$. Let $\vec{c}_\ell$ be the first column of the matrix $Q_{\ell}^{m_i}\left(\frac{1}{m_i}L_i^*\right)$. Using our recurrence relation \eqref{recurrence} we have,
\begin{equation}\label{crec}
\vec{c}_\ell = \frac{(2\ell+m_i-4)\frac{1}{m_i}L_i^*\vec{c}_{\ell-1} - (\ell-1)\vec{c}_{\ell-2}}{\ell+m-3} \qquad \ell\geq 2.
\end{equation}
However Theorem \ref{kreinidentities} tells us that $q^j_{i0} = \delta_{i,j}$ for $0\leq i\leq d$. Therefore equation $\eqref{ELGeg}$ gives us that the entries of $\vert X\vert \vec{c}_\ell$ are the eigenvalues of $Q_{k}^{m_i}\circ\left(\frac{\vert X\vert}{m_i}E_i\right)$, that is, \[c_\ell = \left[\begin{array}{c}
\nicefrac{\theta_{\ell0}}{\vert X\vert}\\\vdots\\\nicefrac{\theta_{\ell d}}{\vert X\vert}
\end{array}\right]\] and thus Sch\"{o}nberg's Theorem is equivalent to $c_\ell\geq 0$ for all integers $\ell\geq 0$. Since $Q_0^m\circ\left(\frac{\vert X\vert}{m_i}E_i\right) = J$ and $Q_1^m\circ\left(\frac{\vert X\vert}{m_i}E_i\right) = \frac{\vert X\vert}{m_i}E_i$, we have
\begin{equation*}
\vec{c}_0 = \vec{e}_0\qquad \vec{c}_1 = \frac{1}{m_i}\vec{e}_i.
\end{equation*}
We now make our first transformation via $\vec{b}_\ell = \sqrt{\Delta_m}\vec{c}_\ell$ where $\sqrt{\Delta_m}$ is the diagonal matrix with $i^\text{th}$ diagonal entry $\sqrt{m_i}$. This transformation turns our recurrence relation into:
\begin{equation}\label{brec}
\vec{b}_\ell = \frac{(2\ell+m_i-4)M\vec{b}_{\ell-1} - (\ell-1)\vec{b}_{\ell-2}}{\ell+m-3} \qquad \ell\geq 2,
\end{equation}
where $M = \frac{1}{m_i}\sqrt{\Delta_m}L_i^*\left(\sqrt{\Delta_m}\right)^{-1}$. Further our initial vectors are
\begin{equation*}
\vec{b}_0 = \vec{e}_0\qquad \vec{b}_1 = \frac{1}{\sqrt{m_i}}\vec{e}_i.
\end{equation*}
The following lemma gives us the spectral decomposition of $M$.
\begin{lem}\label{Mmat}
	Let $M = \frac{1}{m_i}\sqrt{\Delta_m}L_i^*\left(\sqrt{\Delta_m}\right)^{-1}$. Then the set $\left\{\vec{p}_0,\vec{p}_1,\dots,\vec{p}_d\right\}$ with
	\[\vec{p}_j = \left[\begin{array}{c}
	P_{0j}\\
	\sqrt{m_1}P_{1j}\\
	\vdots\\
	\sqrt{m_d}P_{dj}\\
	\end{array}\right]\]
	is an orthogonal set of eigenvectors for $M$ with eigenvalues $m_i^{-1}Q_{ji}$ $(0\leq j\leq d)$.
\end{lem}
\begin{proof}
	Note that Lemma \ref{kitchensink} $(viii')$ tells us that the columns of $P$ are eigenvectors of $L_i^*$ with eigenvalues $Q_{ji}$ ($0\leq j\leq d$). Conjugating $L_i^*$ by $\sqrt{\Delta_m}$ therefore results in a matrix with eigenvectors given by the columns of $\sqrt{\Delta_m}P$ with the same eigenvalues. Further, scaling by $\frac{1}{m_i}$ leaves the eigenvectors unchanged but scales the eigenvalues by $\frac{1}{m_i}$. Finally, our orthogonality relations (Lemma \ref{orthorels}) give us $\Delta_m P = Q^T \Delta_k$ and $PQ = \vert X\vert I$. Therefore
	\[\left(\sqrt{\Delta_m}P\right)^T\left(\sqrt{\Delta_m}P\right) = P^T\Delta_mP = P^TQ^T\Delta_k = \vert X\vert\Delta_k.\]
\end{proof}
Now that our transition matrix has an orthogonal set of eigenvectors, we double the dimension of our vector space in order to make our recurrence relation linear. For $\ell\geq 1$, let 
\begin{equation}\label{tkdef}\mu_\ell = \frac{\ell-1}{\ell+m_i-3};\qquad \vec{y}_\ell = \left[\begin{array}{c}
\vec{b}_{\ell}\\\hdashline[2pt/2pt]
\vec{b}_{\ell-1}
\end{array}\right];\qquad T_\ell = \left[\begin{array}{>{\centering\arraybackslash}p{3cm};{2pt/2pt}>{\centering\arraybackslash}p{3cm}}
$(1+\mu_\ell)M$ & $-\mu_\ell I$\\\hdashline[2pt/2pt]
$I$ & $0$
\end{array}\right].\end{equation}
Then we have
\begin{equation}\label{yrec}
\vec{y}_\ell = T_\ell\vec{y}_{\ell-1};\qquad \vec{y}_1 = \left[\begin{array}{c}
\frac{1}{\sqrt{m_i}}\vec{e}_{i}\\\hdashline[2pt/2pt]
\vec{e}_{0}
\end{array}\right].
\end{equation}
Although $T_\ell$ depends on $\ell$, we may identify some common properties among the eigenvalues and eigenvectors of $T_\ell$ for all values of $\ell>0$. The next few lemmas describe the eigenspaces of $T_\ell$ as well as the action of $T_\ell$ on linear subspaces of our vector space containing our initial vector.
\begin{lem}\label{Tkeig}
	Let $(\lambda,\vec{v})$ be an eigenpair of $M$. Define $\left\{\eta^+,\eta^-\right\}$ be the two roots of the quadratic polynomial $x^2-(1+\mu_\ell)\lambda x +\mu_\ell$. If $\eta^+\neq\eta^-$ then both
	$\left(\eta^+,\left[\begin{array}{c}
	\eta^+\vec{v}\\\hdashline[2pt/2pt]
	\vec{v}
	\end{array}\right]\right)$ and $ \left(\eta^-,\left[\begin{array}{c}
	\eta^-\vec{v}\\\hdashline[2pt/2pt]
	\vec{v}
	\end{array}\right]\right)$
	are eigenpairs of $T_\ell$. If instead $\eta_\lambda^+=\eta_\lambda^-$ then $\left(\eta_\lambda^+,\left[\begin{array}{c}
	\eta_\lambda^+\vec{v}\\\hdashline[2pt/2pt]
	\vec{v}
	\end{array}\right]\right)$ is an eigenpair and $\left[\begin{array}{c}
	\vec{v}\\\hdashline[2pt/2pt]
	\vec{0}
	\end{array}\right]$ is a generalized eigenvector of order two with eigenvalue $\eta$.
\end{lem}
\begin{proof}
	Let $M \vec{v} = \lambda\vec{v}$ and let $\eta$ be given so that $\eta^2-(1+\mu_\ell)\lambda\eta +\mu_\ell=0$. Then
	\[T_\ell\left[\begin{array}{c}
	\eta \vec{v}\\\hdashline[2pt/2pt]
	\vec{v}
	\end{array}\right] = \left[\begin{array}{c}
	(1+\mu_\ell)M(\eta \vec{v}) - \mu_\ell \vec{v}\\\hdashline[2pt/2pt]
	\eta \vec{v}
	\end{array}\right] = \left[\begin{array}{c}
	\left((1+\mu_\ell)\lambda\eta - \mu_\ell\right) \vec{v}\\\hdashline[2pt/2pt]
	\eta \vec{v}
	\end{array}\right] =  \left[\begin{array}{c}
	\eta^2 \vec{v}\\\hdashline[2pt/2pt]
	\eta \vec{v}
	\end{array}\right].\]
	If we have two distinct roots $(\eta^+\neq \eta^-)$ then the vectors $\left[\begin{array}{c}
	\eta^+ \vec{v}\\\hdashline[2pt/2pt]
	\vec{v}
	\end{array}\right]$ and $\left[\begin{array}{c}
	\eta^- \vec{v}\\\hdashline[2pt/2pt]
	\vec{v}
	\end{array}\right]$ result in two distinct eigenvectors. If instead we find that $\eta^+=\eta^-=\eta$, then $(1+\mu_\ell)^2\lambda^2-4\mu_\ell=0$ and thus $\eta = \frac{(1+\mu_\ell)\lambda}{2}$. In this case,
	\[T_\ell\left[\begin{array}{c}
	\vec{v}\\\hdashline[2pt/2pt]
	\vec{0}
	\end{array}\right] = \left[\begin{array}{c}
	(1+\mu_\ell)M(\vec{v})\\\hdashline[2pt/2pt]
	\vec{v}
	\end{array}\right]= \left[\begin{array}{c}
	(1+\mu_\ell)\lambda\vec{v}\\\hdashline[2pt/2pt]
	\vec{v}
	\end{array}\right] = \left[\begin{array}{c}
	\eta \vec{v}\\\hdashline[2pt/2pt]
	\vec{0}
	\end{array}\right]+\left[\begin{array}{c}
	\eta \vec{v}\\\hdashline[2pt/2pt]
	\vec{v}
	\end{array}\right].\]
	Thus $(T_\ell-\eta I)\left[\begin{array}{c}
	\vec{v}\\\hdashline[2pt/2pt]
	\vec{0}
	\end{array}\right] = \left[\begin{array}{c}
	\eta \vec{v}\\\hdashline[2pt/2pt]
	\vec{v}
	\end{array}\right]$ giving us that $\left[\begin{array}{c}
	\vec{v}\\\hdashline[2pt/2pt]
	\vec{0}
	\end{array}\right]$ is a generalized eigenvector of order two; that is, $\left[\begin{array}{c}
	\vec{v}\\\hdashline[2pt/2pt]
	\vec{0}
	\end{array}\right]$ is in the kernel of $\left(T_\ell-\eta I\right)^2$ but not $\left(T_\ell-\eta I\right)$.
\end{proof}
Lemma \ref{Tkeig} gives a complete description of the eigenspaces of our transition matrix $T_\ell$ since we know $M$ is diagonalizable and therefore has a full set of eigenvectors. Further, since the eigenvectors of $M$ are orthogonal, the eigenvectors of $T_\ell$ may be split into pairs where eigenvectors from distinct pairs are orthogonal to each other. The next two lemmas examine these pairs and bound the action of $T_\ell$ on a portion of the subspace spanned by each pair, based solely on the corresponding eigenvalue of $M$.
\begin{lem}\label{realroot}
	Let $\left(\lambda,\vec{p}\right)$ be an eigenpair of $M$ and assume that $(1+\mu_\ell)^2\lambda^2-4\mu_\ell\geq0$ and thus $x^2-(1+\mu_\ell)\lambda x + \mu_\ell$ has only real roots, $\vert\eta^-\vert\leq\vert\eta^+\vert$. Let $\vec{v} = \left[\begin{array}{c}
	a\vec{p}\\\hdashline[2pt/2pt]
	b\vec{p}
	\end{array}\right]$ with $b\neq 0$. There exists a constant $\beta\in\mathbb{R}$ so that $T_\ell \vec{v} = \left[\begin{array}{c}
	\beta\vec{p}\\\hdashline[2pt/2pt]
	a\vec{p}
	\end{array}\right]$. Further, $\lambda \left(\frac{a}{b}\right)\geq0$ and $\vert\eta^+\vert\leq \vert\frac{a}{b}\vert\leq\vert\lambda\vert$ imply $\lambda\left(\frac{\beta}{a}\right)\geq 0$ and $\vert\eta^+\vert\leq \vert\frac{\beta}{a}\vert\leq\vert\lambda\vert$ giving $\vert\vert T_\ell \vec{v}\vert\vert_2\leq \vert \lambda\vert\cdot\vert\vert \vec{v}\vert\vert_2$.
\end{lem}
\begin{proof}
	We begin by noting that since our operator $T_\ell$ is linear, we may assume without loss of generality that $b=1$ and $\vert\vert\vec{p}\vert\vert_2 = 1$ giving as well that $a$ and $\lambda$ must share signs. Since $\eta^+$ and $\eta^-$ are the two (not necessarily distinct) roots of the polynomial $x^2-(1+\mu_\ell)\lambda x + \mu_k$, we know that $(x-\eta^-)(x-\eta^+) = x^2-(1+\mu_\ell)\lambda x + \mu_k$ and therefore $\eta^++\eta^-=(1+\mu_\ell)\lambda$ and $\eta^+\eta^- = \mu_\ell$. Therefore our two roots $\eta^-$ and $\eta^+$ also share signs with $\lambda$. We first consider the case when $\eta^-\neq \eta^+$. In this case, Lemma \ref{Tkeig} tells us that $\eta^+$ and $\eta^-$ are eigenvalues of $T_\ell$ with eigenvectors
	\[\vec{v}^+ = \left[\begin{array}{c}
	\eta^+ \vec{p}\\\hdashline[2pt/2pt]
	\vec{p}
	\end{array}\right];\qquad \vec{v}^-=\left[\begin{array}{c}
	\eta^- \vec{p}\\\hdashline[2pt/2pt]
	\vec{p}
	\end{array}\right].\]
	Therefore we find $\vec{v} = \left(\frac{\eta^--a}{\eta^--\eta^+}\right)\vec{v}^+ + \left(\frac{a-\eta^+}{\eta^--\eta^+}\right)\vec{v}^-$. We may then calculate $T_\ell \vec{v}$ explicitly giving
	\[T_\ell \vec{v} = \left(\frac{\eta^--a}{\eta^--\eta^+}\right)\eta^+\vec{v}^+ + \left(\frac{a-\eta^+}{\eta^--\eta^+}\right)\eta^-\vec{v}^- = \left[\begin{array}{c}
	\beta \vec{p}\\\hdashline[2pt/2pt]
	a\vec{p}
	\end{array}\right]\]
	where $\beta = \left(\frac{\eta^--a}{\eta^--\eta^+}\right)\left(\eta^+\right)^2 + \left(\frac{a-\eta^+}{\eta^--\eta^+}\right)\left(\eta^-\right)^2 = a\left(\eta^++\eta^-\right)-\eta^-\eta^+$. Thus $\frac{\beta}{a} = \eta^+ + \frac{\eta^-}{a}\left(a-\eta^+\right).$
	Since $\eta^-,\eta^+,$ and $a$ all share the same sign and $\vert\eta^+\vert\leq\vert a\vert$, $\frac{\eta^-}{a}\left(a-\eta^+\right)$ must also share the same sign as $\eta^+$. Thus
	\[\left\vert\eta^+\right\vert\leq  \left\vert\eta^+ + \frac{\eta^-}{a}\left(a-\eta^+\right) \right\vert\leq\left\vert\eta^+ + \left(a-\eta^+\right) \right\vert = \vert a\vert\leq \vert\lambda\vert\]
	Similarly, consider the case when $\eta^- = \eta^+ = \eta = \frac{(1+\mu_\ell)\lambda}{2}$. Here, Lemma \ref{Tkeig} gives the eigenvector and generalized eigenvector
	\[\vec{w} = \left[\begin{array}{c}
	\eta \vec{p}\\\hdashline[2pt/2pt]
	\vec{p}
	\end{array}\right];\qquad \vec{w}^*=\left[\begin{array}{c}
	\vec{p}\\\hdashline[2pt/2pt]
	\vec{0}
	\end{array}\right].\]
	Then $\vec{v} = \vec{w} + \left(a-\eta\right)\vec{w}^*$ and thus $T_\ell\vec{v} =  a\vec{w} + \eta\left(a-\eta\right)\vec{w}^* = \left[\begin{array}{c}
	(2a-\eta)\eta\vec{p}\\\hdashline[2pt/2pt]
	a\vec{p}
	\end{array}\right].$
	Therefore $\frac{\beta}{a} = \eta+ \frac{\eta}{a}(a-\eta)$ and as before we find that $\frac{\eta}{a}(a-\eta)$ and $\eta$ share the same sign giving
	\[\vert \eta\vert\leq \left\vert \eta+ \frac{\eta}{a}(a-\eta)\right\vert\leq \left\vert \eta+ (a-\eta)\right\vert\leq\left\vert a\right\vert=\left\vert\lambda\right\vert.\]
	Therefore in both cases we find that $\vert\eta\vert\leq \left\vert\frac{\beta}{a}\right\vert\leq\vert \lambda\vert$, giving
	\[\vert\vert T_\ell \vec{v}\vert\vert^2_2 =\beta^2 + a^2 = \frac{\beta^2}{a^2}a^2 + a^2\leq \lambda^2a^2+\lambda^2 = \lambda^2\vert\vert \vec{v}\vert\vert_2^2.\] 
	Finally, since $\eta^+$ and $\frac{\eta^-}{a}\left(a-\eta^+\right)$ had the same sign in both cases, we must also have $\frac{\beta}{a}$ share the same sign. Thus $\lambda\left(\frac{\beta}{a}\right)\geq 0$.
\end{proof}
\begin{lem}\label{complexroot}
	Let $\left(\lambda,\vec{p}\right)$ be an eigenpair of $M$ and assume that $(1+\mu_\ell)^2\lambda^2-4\mu_\ell<0$ and thus $x^2-(1+\mu_\ell)\lambda x + \mu_\ell$ has no real roots. For any vector $\vec{v} = \left[\begin{array}{c}
	a\vec{p}\\\hdashline[2pt/2pt]
	b\vec{p}
	\end{array}\right]$, we have $\vert\vert T_\ell \vec{v}\vert\vert_2=\sqrt{\mu_\ell}\cdot\vert\vert \vec{v}\vert\vert_2$.
\end{lem}
\begin{proof}
	Let $\eta^+$ and $\eta^-$ be the two roots of $x^2-(1+\mu_\ell)\lambda x + \mu_\ell$. Since $\eta^+$ and $\eta^-$ are not real, $\vert\eta^+\vert = \vert\eta^-\vert = \sqrt{\eta^+\eta^-} = \sqrt{\mu_\ell}$. Therefore every vector in this subspace is rotated and scaled down by a factor of $\sqrt{\mu_\ell}$.
\end{proof}
Now that we have $T_\ell$-invariant subspaces and are able to control the squared norm of the image of certain vectors in these subspaces, we must consider how the the portion of the subspaces described in Lemma \ref{realroot} changes as we iterate $\ell$. This equates to determining how the roots of the polynomial $x^2-(1+\mu_\ell)\lambda + \mu_\ell$ change as we increase $\mu_\ell$ for fixed $\lambda$.
\begin{lem}\label{rootshift}
	Let $\ell\in\bbZ^+$ and $-1<\lambda< 1$ be given. Assume that $x^2-(1+\mu_{\ell+1})\lambda x+\mu_{\ell+1}$ has real roots $x_{\ell+1}^-\leq x_{\ell+1}^+$. Then $x^2-(1+\mu_{\ell})\lambda x+\mu_{\ell}$ also has real roots $x_{\ell}^-$ and $x_{\ell}^+$ with $x_{\ell}^-<x_{\ell+1}^-\leq x_{\ell+1}^+< x_{\ell}^+$.
\end{lem}
\begin{proof}
	Fix $-1<\lambda<1$ and define the multivariate polynomial $p(x,\mu) = x^2-(1+\mu)\lambda x+\mu$ with domain $-1\leq x,\mu\leq 1$. Fix $m>2$ and define $\mu_{\ell} = \frac{\ell -1}{\ell+m-3}$. If $(1+\mu_\ell)^2\lambda^2-4\mu_\ell\geq 0$ we have that $p(x,\mu_\ell)=0$ has real solutions $x^-\leq x^+$. Further, since the leading term of $p(x,\mu_\ell)$ is positive, $p(x,\mu_\ell)<0$ only on the interval $x\in\left(x^-,x^+\right)$. Now consider that $\frac{\partial p(x,\mu)}{\partial \mu} = 1-\lambda x>0$ for all values in our domain. Therefore since $\mu_{\ell+1}>\mu_{\ell}$, we must have that $p(x,\mu_{\ell+1})>p(x,\mu_{\ell})$. Therefore any real solutions of $p(x,\mu_{\ell+1})=0$ must lie strictly between $x^-$ and $x^+$. Finally our requirement $(1+\mu_\ell)^2\lambda^2-4\mu_\ell\geq 0$ reduces to $\mu_{\ell}\leq2-\lambda\pm2\sqrt{1-\lambda}$ since $\mu_{\ell}<1$ for all values of $\ell\in\bbZ^+$. Therefore, since $\mu_{\ell+1}>\mu_{l}$ we find that $p(x,\mu_{\ell+1})$ has real roots only if $p(x,\mu_\ell)$ has real roots.
\end{proof}
With this lemma, we know that the largest absolute value of the roots of $x^2-(1+\mu_\ell)\lambda_j + \mu_\ell$ decreases as $\mu_\ell$ so long as the roots are real. Further, this lemma also implies that if the roots of $x^2-(1+\mu_\ell)\lambda_j + \mu_\ell$ are complex, then $x^2-(1+\mu_{\ell+1})\lambda_j + \mu_{\ell+1}$ must also have complex roots. We will use these two facts as well as the proceeding lemmas to prove our next lemma.
\begin{lem}\label{normbound}
	Suppose we have a feasible parameter set for an association scheme with first and second eigenmatrices $P$ and $Q$. For $0\leq i,j\leq d$ define $\lambda_j = \nicefrac{Q_{j,i}}{m_i}$ and $B_j =\left\{\left[\begin{array}{c}
	a\vec{p}_j\\\hdashline[2pt/2pt]
	b\vec{p}_j
	\end{array}\right]\vert a,b\in\bbR\right\}$ where $\vec{p}_j$ is the $j^\text{th}$ column of $\sqrt{\Delta_m}P$. For $\ell\geq 1$ define $\mu_\ell$, $\vec{y}_\ell$, and $T_\ell$ via equations \eqref{tkdef} and \eqref{yrec}. Then \[\text{proj}_{B_j}(\vec{y}_1) =\frac{1}{\vert X\vert}\left[\begin{array}{c}
	\lambda_j\vec{p}_j\\\hdashline[2pt/2pt]
	\vec{p}_j
	\end{array}\right];\qquad\left\vert\left\vert \left(\prod_{\ell=2}^{\ell^*} T_\ell\right) \text{proj}_{B_j}(\vec{y}_1)\right\vert\right\vert^2_2\leq(1+\lambda_j^2)\frac{k_j}{\vert X\vert}\left(\prod_{\ell=2}^{\ell^*}\gamma_{\ell,j}\right)\]
	where
	\[\gamma_{\ell,j} = \begin{cases}
	\lambda_j^2 & (1+\mu_\ell)^2\lambda_j^2\geq 4\mu_\ell\\
	\mu_\ell & (1+\mu_\ell)^2\lambda_j^2< 4\mu_\ell.
	\end{cases}\]
\end{lem}
\begin{proof}
	Let $\vec{y}_\ell$ given by the recurrence relation \eqref{yrec} for $\ell>1$ with $\vec{y}_1= \left[\begin{array}{c}
	\frac{1}{\sqrt{m_i}}\vec{e}_{i}\\\hdashline[2pt/2pt]
	\vec{e}_{0}
	\end{array}\right]$. We may find an orthogonal basis for $B_j$ via $B_j = \text{span}\left(\left[\begin{array}{c}
	\vec{p}_j\\\hdashline[2pt/2pt]
	\vec{0}
	\end{array}\right],\left[\begin{array}{c}
	\vec{0}\\\hdashline[2pt/2pt]
	\vec{p}_j
	\end{array}\right]\right)$. Noting that $\left(\sqrt{\Delta_m}P\right)^T\left(\sqrt{\Delta_m}P\right) = \vert X\vert\Delta_k$ and thus $\vert\vert \vec{p}_j\vert\vert_2^2 = \vert X\vert k_j$, this gives 
	\[\text{proj}_{B_j}(\vec{y}_1) = \frac{1}{k_j\vert X\vert}\left[\begin{array}{c}
	P_{i,j}\vec{p}_j\\\hdashline[2pt/2pt]
	P_{0,j}\vec{p}_j
	\end{array}\right] =\frac{1}{\vert X\vert}\left[\begin{array}{c}
	\frac{P_{i,j}}{k_j}\vec{p}_j\\\hdashline[2pt/2pt]
	\vec{p}_j
	\end{array}\right] = \frac{1}{\vert X\vert}\left[\begin{array}{c}
	\lambda_j\vec{p}_j\\\hdashline[2pt/2pt]
	\vec{p}_j
	\end{array}\right].\]
	Next Lemma \ref{rootshift} implies that the polynomial $x^2-(1+\mu_\ell)\lambda_j+\mu_\ell$ has complex roots if and only if $x^2-(1+\mu_{\ell'})\lambda_j+\mu_{\ell'}$ has complex roots for all $\ell'>\ell$. Therefore let $h$ be the largest integer less than or equal to $l^*$ for which $x^2-(1+\mu_h)\lambda_j+\mu_h$ has real roots. Let $2\leq \ell\leq h$ and let $\eta_\ell$ be the largest root (in absolute value) of $x^2-(1+\mu_\ell)\lambda_j+\mu_\ell$. Further assume that there exists constants $a_\ell$ and $b_\ell$ such that $\text{proj}_{B_j}\left(\vec{y}_{\ell-1}\right) = \left[\begin{array}{c}
	a_\ell\vec{p}_j\\\hdashline[2pt/2pt]
	b_\ell\vec{p}_j
	\end{array}\right]$ where $\lambda_j\left(\frac{a_\ell}{b_\ell}\right) \geq 0$ and $\vert \eta_\ell\vert\leq\vert \frac{a_\ell}{b_\ell}\vert\leq\vert\lambda_j\vert$. Then Lemma \ref{realroot} tells us that there exists a $\beta\in\mathbb{R}$ such that $\text{proj}_{B_j}\left(\vec{y}_\ell\right) = T_\ell\left(\text{proj}_{B_j}\left(\vec{y}_{\ell-1}\right)\right) =\left[\begin{array}{c}
	\beta\vec{p}_j\\\hdashline[2pt/2pt]
	a\vec{p}_j
	\end{array}\right]$ where
	$\lambda\left(\frac{\beta}{a}\right)\geq 0$, $\vert\eta_\ell\vert\leq \vert\frac{\beta}{a}\vert\leq\vert\lambda\vert$, and
	\[\left\vert\left\vert \text{proj}_{B_j}\left(\vec{y}_\ell\right)\right\vert\right\vert_2^2\leq \vert \lambda\vert^2\cdot\left\vert\left\vert \text{proj}_{B_j}\left(\vec{y}_{\ell-1}\right)\right\vert\right\vert_2^2.\]
	Lemma also $\ref{rootshift}$ tells us that if $\ell<h$ then $\vert\eta_{\ell+1}\vert<\vert\eta_{\ell}\vert$ where $\eta_{\ell+1}$ is the largest root in absolute value of the polynomial $x^2-(1+\mu_{\ell+1})\lambda_j+\mu_{\ell+1}$. Therefore, either $\ell=h$ or there exists constants $a_{\ell+1}$ and $b_{\ell+1}$ so that $\text{proj}_{B_j}\left(\vec{y}_{\ell}\right) = \left[\begin{array}{c}
	a_{\ell+1}\vec{p}_j\\\hdashline[2pt/2pt]
	b_{\ell+1}\vec{p}_j
	\end{array}\right]$ where $\lambda_j\left(\frac{a_{\ell+1}}{b_{\ell+1}}\right) \geq 0$ and $\vert \eta_\ell\vert\leq\vert \frac{a_{\ell+1}}{b_{\ell+1}}\vert\leq\vert\lambda_j\vert$. Finally note that $\text{proj}_{B_j}\left(\vec{y}_{1}\right) = \left[\begin{array}{c}
	\lambda_j\vec{p}_j\\\hdashline[2pt/2pt]
	\vec{p}_j
	\end{array}\right]$ and therefore $a_2 = \lambda_j$ and $b_2=1$, satisfying $\lambda_j\left(\frac{a_{2}}{b_{2}}\right) \geq 0$ and $\vert \eta_\ell\vert\leq\vert \frac{a_{2}}{b_{2}}\vert\leq\vert\lambda_j\vert$. Therefore, by induction, we have that
	\[\left\vert\left\vert \left(\prod_{\ell=2}^{h} T_\ell\right) \text{proj}_{B_j}(\vec{y}_1)\right\vert\right\vert^2_2\leq \left\vert\left\vert \text{proj}_{B_j}\left(\vec{y}_1\right)\right\vert\right\vert^2_2\left(\prod_{\ell=2}^{h}\lambda_j^2\right)= (1+\lambda_j^2)\frac{k_j}{\vert X\vert}\left(\prod_{\ell=2}^{h}\lambda_j^2\right)\]
	Now let $h<\ell\leq \ell^*$, and define $\vec{v} = \left(\prod_{\ell=2}^{h} T_\ell\right) \text{proj}_{B_j}(\vec{y}_1)$. Then Lemma \ref{complexroot} gives us that
	\[\left\vert\left\vert \left(\prod_{\ell=h+1}^{\ell^*} T_\ell\right) \vec{v}\right\vert\right\vert^2_2\leq \left\vert\left\vert \vec{v}\right\vert\right\vert^2_2\left(\prod_{\ell=h+1}^{\ell^*}\mu_\ell\right)\leq (1+\lambda_j^2)\frac{k_j}{\vert X\vert}\left(\prod_{\ell=2}^{h}\lambda_j^2\right)\left(\prod_{\ell=h+1}^{\ell^*}\mu_\ell\right).\]
\end{proof}
We are now ready to prove the main theorem of this section, using Lemma \ref{normbound} to control the norm of the transient vectors at each iteration.
\degbnd
\begin{proof}
	Let $\vec{y}_\ell$ given by the recurrence relation \eqref{yrec} for $\ell>1$ with $\vec{y}_1= \left[\begin{array}{c}
	\frac{1}{\sqrt{m_i}}\vec{e}_{i}\\\hdashline[2pt/2pt]
	\vec{e}_{0}
	\end{array}\right]$. Consider that the sign of $\left[\vec{y}_\ell\right]_i$ is negative if and only if there is a negative entry in either $\vec{c}_k$ or $\vec{c}_{k-1}$ as defined in equation \eqref{crec}. Therefore the requirements that $\theta_{\ell,j}\geq 0$ as seen in Theorem \ref{schoen-as} are equivalent to the requirement that $\vec{y}_k$ has only non-negative entries for all $k\geq 0$.
	Define subspaces $B_j = \text{span}\left(\left[\begin{array}{c}
	\vec{p}_j\\\hdashline[2pt/2pt]
	\vec{0}
	\end{array}\right],\left[\begin{array}{c}
	\vec{0}\\\hdashline[2pt/2pt]
	\vec{p}_j
	\end{array}\right]\right)$ where $\vec{p}_j$ is the $j^\text{th}$ column of $\sqrt{\Delta_m}P$ where $\bbR^{2d+2} = \bigoplus_{j=0}^d B_j$. Lemma \ref{normbound} then tell us that
	\[\text{proj}_{B_j}(\vec{y}_1) = \frac{1}{\vert X\vert}\left[\begin{array}{c}
	\lambda_j\vec{p}_i\\\hdashline[2pt/2pt]
	\vec{p}_i
	\end{array}\right] \]
	allowing us to split $y_1$ into
	\[y_1 = \frac{1}{\vert X\vert}\left[\begin{array}{c}
	\sqrt{\Delta_m}\vec{1}\\\hdashline[2pt/2pt]
	\sqrt{\Delta_m}\vec{1}
	\end{array}\right] + \frac{1}{\vert X\vert}\sum_{j=1}^d\left[\begin{array}{c}
	\lambda_j\vec{p}_j\\\hdashline[2pt/2pt]
	\vec{p}_j
	\end{array}\right]\]
	giving us
	\[\vec{y}_{\ell^*+1} = \left(\prod_{\ell=2}^{\ell^*+1}T_\ell\right)\vec{y}_1 = \frac{1}{\vert X\vert}\left[\begin{array}{c}
	\sqrt{\Delta_m}\vec{1}\\\hdashline[2pt/2pt]
	\sqrt{\Delta_m}\vec{1}
	\end{array}\right] + \frac{1}{\vert X\vert}\sum_{j=1}^d\left(\prod_{\ell=2}^{\ell^*+1}T_\ell\right)\left[\begin{array}{c}
	\lambda_j\vec{p}_i\\\hdashline[2pt/2pt]
	\vec{p}_i
	\end{array}\right].\]
	Note that the smallest element of $\frac{1}{\vert X\vert}\left[\begin{array}{c}
	\sqrt{\Delta_m}\vec{1}\\\hdashline[2pt/2pt]
	\sqrt{\Delta_m}\vec{1}
	\end{array}\right]$ is $\frac{1}{\vert X\vert}$ and thus in order for $\vec{y}_{\ell^*+1}$ to have a negative element, we must have 
	\[\left\vert\left\vert \frac{1}{\vert X\vert}\sum_{j=1}^d\left(\prod_{\ell=2}^{\ell^*+1}T_\ell\right)\left[\begin{array}{c}
	\lambda_j\vec{p}_i\\\hdashline[2pt/2pt]
	\vec{p}_i
	\end{array}\right]\right\vert\right\vert^2_2>\frac{1}{\vert X\vert^2}.\]
	Again using Lemma \ref{normbound}, we have
	\[\begin{aligned}\left\vert\left\vert \frac{1}{\vert X\vert}\sum_{j=1}^d\left(\prod_{\ell=2}^{\ell^*+1}T_\ell\right)\left[\begin{array}{c}
	\lambda_j\vec{p}_i\\\hdashline[2pt/2pt]
	\vec{p}_i
	\end{array}\right]\right\vert\right\vert^2_2 \leq \frac{1}{\vert X\vert}\sum_{j=1}^d v_j(1+\lambda_j^2)\left(\prod_{i=2}^{\ell^*+1}\gamma_{\ell,j}\right)
	\end{aligned}\]
	where $\hat{\vec{b}}_j = \frac{\vec{p}_j}{\vert \vert \vec{p}_j\vert\vert_2}$. Therefore, if we have
	\[\sum_{j=1}^d v_j\lambda_j^{2\ell^*}(1+\lambda_j^2)\leq\frac{1}{\vert X\vert}\]
	then we guarantee $y_{\ell^*+1}$ has no negative entry. Finally since the bottom half of $y_{\ell^*+1}$ equals the top half of $y_{\ell^*}$, we may assume that any negative entry of $y_{\ell^*}$ appears in the bottom half, implying that $y_{\ell^*-1}$ has a negative entry in the top half. Thus checking  the first $\ell^*-1$ conditions is sufficient.
\end{proof}
\begin{cor}\label{maxlambda}
	Suppose we have a feasible parameter set for an association scheme with first and second eigenmatrices $P$ and $Q$. Let $0\leq i\leq d$ be given and define $\lambda_j:=\frac{Q_{j,i}}{m_i}$. Further assume $1=\lambda_0>\vert\lambda^*\vert\geq\vert\lambda_j\vert$ for $0<j\leq d$. Then define
	\[\ell^*=\left\lceil\frac{\ln\left[(1+(\lambda^*)^2)\vert X\vert(\vert X\vert-1)\right]}{-2\ln(\lambda^*)}\right\rceil.\]
	If $\vert\lambda^*\vert^2\geq \frac{\ell^*}{\ell^*+m_i-2}$ then $\theta_{\ell,j}\geq 0$ is implied by FC1 for $\ell\geq \ell^*$ and $0\leq j\leq d$.
\end{cor}
\begin{proof}
	As long as $\vert\lambda^*\vert^2$ is greater than both $\vert\lambda_j\vert^2$ and $\mu_{\ell}$ for $2\leq\ell\leq x$,
	\[\sum_{j=1}^d k_j\left(1+\lambda_j^2\right)\left(\prod_{\ell=2}^{x} \gamma_{x,j}\right)\leq(\lambda^*)^{2x-2}\left(1+(\lambda^*)^2\right)\sum_{j=1}^d v_j =(\lambda^*)^{2x-2}\left(1+(\lambda^*)^2\right)(\vert X\vert -1). \]
	Solving 
	\[(\lambda^*)^{2x-2}\left(1+(\lambda^*)^2\right)(\vert X\vert -1)\leq\frac{1}{\vert X\vert}\]
	for $x$ gives
	\[x\geq\frac{\ln\left[(1+(\lambda^*)^2)\vert X\vert(\vert X\vert-1)\right]}{-2\ln(\lambda^*)}+1.\]
	Thus for $\ell^*=\left\lceil\frac{\ln\left[(1+(\lambda^*)^2)\vert X\vert(\vert X\vert-1)\right]}{-2\ln(\lambda^*)}\right\rceil$, $\ell^*+1$ is the smallest integer for which our inequality holds. Using Theorem \ref{degreebound}, as long as $\vert\lambda^*\vert^2\geq\mu_{\ell^*+1}$, we have our result.
\end{proof}
\subsection*{Example}
Consider the feasible parameter set with first and second eigenmatrices
\[P = \left[\begin{array}{rrrr}
1 & 100 & 240 & 100\\
1 & 37 & -12 & -26\\
1 & 2 & -12 & 9\\
1 & -5 & 9 & -5
\end{array}\right],\qquad Q = \left[\begin{array}{rrrr}
1 & 20 & 180 & 240\\
1 & \nicefrac{37}{5} & \nicefrac{18}{5} & -12\\
1 & -1 & -9 & 9\\
1 & \nicefrac{-26}{5} & \nicefrac{91}{5} & -12
\end{array}\right].\]
If realizable, the association scheme with this parameter set would be a 3-class primitive $Q$-polynomial association scheme. Using the first eigenspace for our Gram matrix, that is $i=1$ in Theorem \ref{schoen-as}, we find $\lambda_0 = 1$, $\lambda_1 = \frac{37}{100}$, $\lambda_2 = -\frac{1}{20}$, and $\lambda_3 = -\frac{26}{100}$ where $\lambda_j = \nicefrac{Q_{j1}}{Q_{01}}$. Noting that $(1+\mu_\ell)^2\lambda^2-4\mu_\ell<0$ if and only if $\mu_\ell = \frac{\ell-1}{\ell+m-3}>2-\vert\lambda\vert-2\sqrt{1-\vert\lambda\vert}$. For $1\leq j\leq d$ define $\ell_j$ as the largest integer for which $\frac{\ell-1}{\ell+m-3}\leq2-\lambda-2\sqrt{1-\lambda}$. Then we find $\ell_1=\ell_2=\ell_3=1$ giving
\[\begin{aligned}\sum_{j=1}^3k_j\left(1+\lambda_j^2\right)\left(\prod_{\ell=2}^{x+1}\gamma_{\ell,j}\right) &= \left(\prod_{\ell=2}^{x+1}\mu_\ell\right)\left(440+100\left(\frac{37}{100}\right)^2+240\left(\frac{1}{20}\right)^2+100\left(\frac{26}{100}\right)^2\right)\\
&=\left(\prod_{\ell=2}^{x+1}\mu_\ell\right)\frac{18843}{40}\end{aligned}\]
Noting that
\[\left(\prod_{\ell=2}^8\mu_\ell\right)\frac{18843}{40}\approx 0.00098<\frac{1}{441},\]
we have that the conditions $\theta_{\ell j}\geq 0$ are vacuous for this parameter set whenever $\ell\geq 7$. Below we list $\theta_{\ell j}$ for $0\leq \ell\leq 6$ and $0\leq j\leq 3$, listing only the first two decimal places for readability:
\[\left[\begin{array}{cccccrc}
441 & 0 & 0 & 4.95 & 0.43 & -0.11 & 0.93 \\
0 & 22.05 & 4.5 & 0.38 & 0.67 & 0.84 & 0.97 \\
0 & 0 & 1.95 & 1.09 & 0.81 & 1 & 1.04 \\
0 & 0 & 0 & 0.97 & 1.17 & 1.02 & 0.98 
\end{array}\right].\]
Note that $\theta_{50} = -0.11<0$ and therefore this parameter set is not realizable.

\section{Cometric Association Schemes}\label{cometricGeg}
In this section, we restrict to the case of cometric association schemes and explicitly compute eigenvalues of the form $\theta_{\ell,j}$ as defined in Theorem \ref{schoen-as}. We will compute $\theta_{\ell,j}$ for $2\leq \ell\leq 5$ and $0\leq j\leq d$ as well as $\theta_{6,0}$. Theorem \ref{schoen-as} tells us that each eigenvalue must be non-negative, and thus we derive more feasibility conditions on the parameters of a cometric association scheme. Many of these feasibility conditions will be implied by our previous conditions FC1, FC2, and FC3, however there are some which are independent of these three conditions. We will examine one such example closely in the section that follows. Suppose we have a feasible parameter set for a $Q$-polynomial association scheme with Krein array $\left\{m,b^*_1,\dots,b^*_{d-1};1,c_2^*\dots,c^*_{d}\right\}$. As before, let $\theta_{\ell,j}$ denote the eigenvalue of $Q_\ell^m\circ\left(\frac{\vert X\vert}{m}E_1\right)$ on the eigenspace $V_j$ for $\ell\geq0$ and $0\leq j\leq d$, allowing ourselves to suppress the comma when the meaning is clear. From our initial two Gegenbauer polynomials, we know
\[\theta_{0i}= \vert X\vert\delta_{0i};\qquad \theta_{1i} =\frac{\vert X\vert}{m}\delta_{1i}.\]
Using equation \eqref{gegprop} and our Krein array, we have
\begin{equation}\label{thetarec}
\theta_{\ell i}= \frac{(2\ell+m-4)(c_{i}^*\theta_{\ell-1,i-1} +a_i^*\theta_{\ell-1,i}+b_{i}^*\theta_{\ell-1,i+1}) - (\ell-1)m\theta_{\ell-2,i}}{m(\ell+m-3)}.
\end{equation}
Before listing the eigenvalues, we note that many of the conditions $\theta_{\ell i}\geq 0$ will be implied by either the Krein conditions FC1 or the cometric requirement on our parameters. Consider the following lemma:
\begin{lem}
	Suppose we have a feasible parameter set for a $Q$-polynomial association scheme with Krein array $\left\{m,b^*_1,\dots,b^*_{d-1};1,c_2^*\dots,c^*_{d}\right\}$. For $\ell\geq 0$, define $\theta_{\ell,j}$ via equation \eqref{thetarec} with $\theta_{0i}=\vert X\vert\delta_{0i}$ and $\theta_{1i}= \frac{\vert X\vert}{m}\delta_{1i}$. Then $\theta_{\ell,i} = 0$ for $i>\ell$ and FC1 implies $\theta_{\ell,i}\geq 0$ for $i\in\left\{\ell-1,\ell\right\}$.
\end{lem}
\begin{proof}
	We prove this by induction, showing first that our cometric requirement implies $\theta_{\ell,i}=0$ for $i>\ell$, $\ell\geq 0$ and then the conditions FC1 imply $\theta_{\ell,\ell}$ and $\theta_{\ell,\ell-1}$ are both non-negative. First note from our initial conditions that $\theta_{0i} = 0$ for $i>0$. Now, let $\ell\geq 1$ be given and assume that $\theta_{\ell,i}= 0$ for $i>\ell$. Then choose $i>\ell+1$ and from equation \eqref{thetarec},
	\[\theta_{\ell+1,i}= \frac{(2\ell+m)(c_{i}^*\theta_{\ell,i-1} +a_i^*\theta_{\ell,i}+b_{i}^*\theta_{\ell,i+1}) - \ell m\theta_{\ell-1,i}}{m(\ell+m-2)}.\]
	However if $i>\ell+1$ then by our induction hypothesis, $\theta_{\ell,i-1} = \theta_{\ell,i} = \theta_{\ell,i+1} = \theta_{\ell-1,i} = 0$, thus $\theta_{\ell+1,i} = 0$. For the remaining two conditions, note that $\theta_{10}\geq 0$ and $\theta_{11}\geq 0$ are both vacuously true. Now let $\ell\geq 1$ be given and assume $\theta_{\ell,\ell-1}\geq 0$ and $\theta_{\ell,\ell}\geq 0$. Then
	\[\begin{aligned}\theta_{\ell+1,\ell+1}&= \frac{(2\ell+m)(c_{\ell+1}^*\theta_{\ell,\ell} +a_{\ell+1}^*\theta_{\ell,\ell+1}+b_{\ell+1}^*\theta_{\ell,\ell+2}) - \ell m\theta_{\ell-1,\ell+1}}{m(\ell+m-2)} = \frac{(2\ell+m)c_{\ell+1}^*\theta_{\ell,\ell}}{m(\ell+m-2)}\\
	\theta_{\ell+1,\ell}&= \frac{(2\ell+m)(c_{\ell}^*\theta_{\ell,\ell-1} +a_{\ell}^*\theta_{\ell,\ell}+b_{\ell-1}^*\theta_{\ell,\ell+1}) - \ell m\theta_{\ell-1,\ell}}{m(\ell+m-2)} = \frac{(2\ell+m)\left(c_\ell^*\theta_{\ell,\ell-1}+a_\ell^*\theta_{\ell,\ell}\right)}{m(\ell+m-2)}.\end{aligned}\]
	Therefore as long as $a_\ell^*,c_\ell^*,c_{\ell+1}^*\geq 0$ (FC1), then $\theta_{\ell+1,\ell+1}\geq 0$ and $\theta_{\ell+1,\ell}\geq 0$.
\end{proof}
Due to this lemma, we know that for feasible parameter set for a cometric association scheme and any choice of $\ell\geq 0$, the condition $\theta_{\ell,i}\geq 0$ will be implied by FC1 or the cometric property for $i\geq \ell-1$. Therefore we will omit $\theta_{\ell,i}$ for $i>\ell$ in the discussion that follows, listing $\theta_{\ell,\ell}$ and $\theta_{\ell,\ell-1}$ only to assist in calculating eigenvalues from higher degree polynomials. In each case, we will use our Krein parameters (primarily those from the Krein array) to calculate the eigenvalues and note when our feasibility condition FC1 is sufficient to imply $\theta_{\ell,i}\geq 0$. At the end of the section, we will summarize any of the conditions which are not implied by FC1, noting that these are our (potentially) new constraints on the parameters of a cometric scheme. For convenience we extend our Krein array to include $a_i^*,c_i^*,$ and $b_i^*$ for all $i\in\mathbb{Z}^+$ noting that $b_{j-1}^* = c_j^*=a_j^*=0$ for $j>d$. We will also use Lemma \eqref{kreinidentity} when convenient, so we assume that our Krein parameters satisfy the condition
\begin{equation}\label{kreinid}\sum_{l=0}^d q_{ij}^lq_{lk}^m = \sum_{l=0}^dq_{il}^mq_{jk}^l.\end{equation}
\subsection*{Degree 2 constraint}
\[\frac{\theta_{20}}{\vert X\vert}  = 0;\qquad\frac{\theta_{21}}{\vert X\vert}  = \frac{a_1^*}{m(m-1)};\qquad\frac{\theta_{22}}{\vert X\vert} = \frac{c_2^*}{m(m-1)}.\]
Each condition $\theta_{2i}\geq 0$ is implied by FC1 and thus we have no new restrictions from this case.
\subsection*{Degree 3 constraint}
\[\frac{\theta_{30}}{\vert X\vert} = \frac{\left(m+2\right)a_1^*}{m^2\left(m-1\right)};\qquad
\frac{\theta_{31}}{\vert X\vert} = \frac{-2m\left(m-1\right)+\left(m+2\right)\left(\left(a_1^*\right)^2+b_1^*c_2^*\right)}{m^3\left(m-1\right)};\]
\[\frac{\theta_{32}}{\vert X\vert} = \frac{\left(m+2\right)c_2^*\left(a_1^*+a_2^*\right)}{m^3\left(m-1\right)};\qquad
\frac{\theta_{33}}{\vert X\vert}= \frac{\left(m+2\right)c_2^*c_3^*}{m^3\left(m-1\right)}.\]
Here, $\theta_{31}\geq0$ is not implied by FC1. Therefore we have the additional constraint
\begin{equation}\label{Co31}\left(a_1^*\right)^2 + b_1^*c_2^* \geq\frac{2m(m-1)}{m+2}\end{equation}
\subsection*{Degree 4 constraint}
\[\frac{\theta_{40}}{\vert X\vert} = \frac{\left(-2m\left(m-1\right)+\left(m+2\right)\left(\left(a_1^*\right)^2+b_1^*c_2^*\right)\right)\left(m+4\right)}{\left(m^2-1\right)m^3}\]
\[\frac{\theta_{41}}{\vert X\vert} = \frac{\left(-4a_1^*m + \left(\left(a_1^*\right)^3+\left(2a_1^*+a_2^*\right)b_1^*c_2^*\right)\left(m+4\right)\right)\left(m+2\right)}{\left(m^2-1\right)m^4}\]
\[\frac{\theta_{42}}{\vert X\vert} = \frac{\left(-4m\left(m-2\right)+\left(\left(a_1^*\right)^2+2a_1^*a_2^*+c_2^*q_{22}^2\right)\left(m+4\right)\right)c_2^*\left(m+2\right)}{\left(m^2-1\right)m^4}\]
\[\frac{\theta_{43}}{\vert X\vert} = \frac{\left(m+4\right)\left(m+2\right)c_3^*c_2^*\left(a_1^*+a_2^*+a_3^*\right)}{\left(m^2-1\right)m^4}\]
\[\frac{\theta_{44}}{\vert X\vert} = \frac{\left(m+4\right)\left(m+2\right)c_4^*c_3^*c_2^*}{\left(m^2-1\right)m^4}\]
First, note that we used equation \eqref{kreinid} with $j=k=1$ and $i=m=2$ to reduce $\theta_{42}$. Now, since $\theta_{20} = 0$, $\theta_{40} = \frac{(m+4)\theta_{31}}{m+1}$ and thus $\theta_{40}\geq 0$ is equivalent to $\theta_{31}\geq 0$ and we will omit this constraint. We therefore find only two new conditions: $\theta_{41}\geq 0$ and $\theta_{42}\geq 0$, both of which are not implied by FC1.
\begin{equation}\label{Co41}
\left(a_1^*\right)^2 + b_1^*c_2^*\left(2+\frac{a_2^*}{a_1^*}\right)\geq \frac{4m}{m+4}\qquad \text{whenever }a_1^*>0;
\end{equation}
\begin{equation}\label{Co42}
\left(a_1^*\right)^2+2a_1^*a_2^*+c_2q^2_{22}\geq \frac{4m(m-2)}{m+4}.
\end{equation}
\subsection*{Degree 5 constraint}
\[\frac{\theta_{50}}{\vert X\vert} = \frac{\left(-4a_1^*m\left(2m-3\right) + \left(\left(a_1^*\right)^3+\left(2a_1^*+a_2^*\right)b_1^*c_2^*\right)\left(m+6\right)\right)\left(m+4\right)}{m^4\left(m^2-1\right)}\]
\[\begin{aligned}\frac{\theta_{51}}{\vert X\vert} = &\frac{6m^2(m-1)(m-4)+(m+4)(m+6)\left(\left(3a_1^*\left(a_1^*+a_2^*\right)+c_2^*q_{22}^2\right)b_1^*c_2^*+\left(a_1^*\right)^4\right)}{m^5\left(m^2-1\right)}\\
&-\frac{m(m+4)(7m-18)\left(\left(a_1^*\right)^2+b_1^*c_2^*\right)}{m^5\left(m^2-1\right)}\end{aligned}\]
\[\begin{aligned}\frac{\theta_{52}}{\vert X\vert\left(m+4\right)c_2^*} = &\frac{(m+6)\left((a_1^*+a_2^*)^3+2\left(c_2^*q_{22}^2-\left(a_2^*\right)^2\right)\left(a_1^*+a_2^*\right)+b_2^*c_3^*\left(a_3^*-a_1^*\right)-ma_2^*\right)}{m^5\left(m^2-1\right)}\\
&-\frac{6\left(a_1^*+a_2^*\right)m(m-4)}{m^5\left(m^2-1\right)}\end{aligned}\]
\[\frac{\theta_{53}}{\vert X\vert} = \frac{\left(-3\left(3m-2\right)+\left(\sum_{i=1}^3\left(b_i^*c_{i+1}^*+a_i^*\sum_{j=i}^3a_j^*\right)\right)\left(m+6\right)\right)\left(m+4\right)c_2^*c_3^*}{m^5\left(m^2-1\right)}\]
\[\frac{\theta_{54}}{\vert X\vert} = \frac{\left(a_1^*+a_2^*+a_3^*+a_4^*\right)c_2^*c_3^*c_4^*\left(m+4\right)\left(m+6\right)}{m^5\left(m^2-1\right)}\]
\[\frac{\theta_{55}}{\vert X\vert} = \frac{c_2^*c_3^*c_4^*c_5^*\left(m+4\right)\left(m+6\right)}{m^5\left(m^2-1\right)}\]
In this case we find four new conditions arising from $\theta_{5i}\geq 0$ for $0\leq i\leq 3$. They are,
\begin{equation}\label{Co50}
\left(a_1^*\right)^2 + b_1^*c_2^*\left(2 + \frac{a_2^*}{a_1^*}\right)\geq \frac{4m(2m-3)}{m+6}.
\end{equation}
\begin{equation}\label{Co51}
\frac{6m(m-1)(m-4)}{(m+4)(m+6)}+\frac{\left(3a_1^*\left(a_1^*+a_2^*\right)+c_2q_{22}^2\right)b_1^*c_2^*+\left(a_1^*\right)^4}{m}\geq \frac{(7m-18)\left(\left(a_1^*\right)^2+b_1^*c_2^*\right)}{m+6}
\end{equation}
\begin{equation}\label{Co52}
\left(a_1^*\right)^2+2a_1^*a_2^*-\left(a_2^*\right)^2+2c_2^*q_{22}^2+\frac{b_2^*c_3^*\left(a_3^*-a_1^*\right)-ma_2^*}{a_1^*+a_2^*}\geq\frac{6m(m-4)}{m+6}
\end{equation}
\begin{equation}\label{Co53}
\sum_{i=1}^3\left(b_i^*c_{i+1}^* + a_i^*\sum_{j=i}^3 a_j^*\right)\geq \frac{3(3m-2)}{m+6}.
\end{equation}
Note that the inequality $\eqref{Co41}$ is implied by the inequality $\eqref{Co50}$ for $m>2$.
\subsection*{Degree 6 constraint}
Here, we list only $\theta_{60}$ as we will use this bound in section \ref{4classbip}.
\[\begin{aligned}\frac{\theta_{60}}{\vert X\vert( m+6)} = &\frac{16m^2(m-2)(m-1) + \left(\left(a_1^*\right)^4 + \left(3a_1^*\left(a_1^*+a_2^*\right)+c_2^*q_{22}^2\right)b_1^*c_2^*\right)(m+8)(m+4)}{m^5(m^2-1)(m+3)}\\
&-\frac{12\left(\left(a_1^*\right)^2+b_1^*c_2^*\right)(m-2)(m+4)m}{m^5(m^2-1)(m+3)}
\end{aligned}\]
This results in the final condition that
\begin{equation}\label{Co60}
\frac{16m(m-1)}{(m+4)(m+8)} + \frac{\left(a_1^*\right)^4 + \left(3a_1^*\left(a_1^*+a_2^*\right)+c_2^*q_{22}^2\right)b_1^*c_2^*}{(m-2)m}\geq \frac{12\left(\left(a_1^*\right)^2+b_1^*c_2^*\right)}{m+8}.
\end{equation}
In summary, we have the following theorems where in each case we assume the Krein parameters fulfill the condition FC1. We omit the inequality coming from $\theta_{41}$ as we may assume $m>2$ for all cases we are interested in.
\cometricbounds
\begin{comment}
\begin{thm}\label{cometricbnds}
Suppose we have a feasible parameter set for a cometric association scheme with Krein array $\left\{m,b^*_1,\dots,b^*_{d-1};1,c_2^*\dots,c^*_{d}\right\}$. Then the scheme is realizable only if
\begin{enumerate}[label=(\roman*)]
\item $\left(a_1^*\right)^2 + b_1^*c_2^* \geq\frac{2m(m-1)}{m+2},$
\item $\left(a_1^*\right)^2+2a_1^*a_2^*+c_2q^2_{22}\geq \frac{4m(m-2)}{m+4},$
\item $TBD,$
\item $\sum_{i=1}^3\left(b_i^*c_{i+1}^* + a_i^*\sum_{j=i}^3 a_j^*\right)\leq \frac{3(3m-2)}{m+6}.$
\item $\frac{16m(m-1)}{(m+4)(m+8)} + \frac{\left(a_1^*\right)^4 + \left(3a_1^*\left(a_1^*+a_2^*\right)+c_2^*q_{22}^2\right)b_1^*c_2^*}{(m-2)m}\geq \frac{12\left(\left(a_1^*\right)^2+b_1^*c_2^*\right)}{m+8},$
\end{enumerate}
Additionally, if $a_1^*>0$ then,
\begin{enumerate}[label=(\roman*)]
\addtocounter{enumi}{5}
\item $\left(a_1^*\right)^2 + b_1^*c_2^*\left(2 + \frac{a_2^*}{a_1^*}\right)\geq \frac{4m(2m-3)}{m+6},$
\item $TBD.$
\end{enumerate}
\end{thm}
\end{comment}
\begin{proof}
	The table below gives the eigenvalue requirements corresponding to each statement.
	\[	\begin{tabular}{c|c|c|c|c|c|c|c}
	Constraint & $(i)$ & $(ii)$ & $(iii)$ & $(iv)$ & $(v)$ &$(vi)$ & $(vii)$\\\hline
	Eigenvalue restriction & $\theta_{30}\geq 0$ & $\theta_{42}\geq 0$ & $\theta_{51}\geq 0$&$\theta_{53}\geq 0$&$\theta_{60}\geq 0$	&$\theta_{50}\geq 0$ &$\theta_{52}\geq 0$\\	
	\end{tabular}\]
\end{proof}
Dr. Williford maintains a list of small ($\vert X\vert<10000$) feasible parameter sets for cometric schemes including primitive cometric schemes with 3 classes and $Q$-bipartite schemes with 4 classes. Using these lists, we find nine $3$-class primitive cometric schemes which are ruled out by Theorem \ref{cometricbnds} $(vi)$ and 11 $4$-class $Q$-bipartite schemes which are ruled out by Theorem \ref{cometricbnds} $(v)$. They are as follows, listed as tuples of the form $\left(\vert X\vert,m_1\right)$:
\begin{itemize}
	\item $3$-class primitive schemes ruled out by Theorem \ref{cometricbnds} $(vi)$
	\[\begin{aligned}\left\{(441,20),(576,23),(729,26),(1015,28),(1240,30),(1548,35),(1836,35),(1944,29),(1976,25)\right\}.\end{aligned}\]
	\item $4$-class $Q$-bipartite schemes
	\begin{itemize}
		\item ruled out by Theorem \ref{cometricbnds} $(v)$,
		\[\left\{(4464,24),(4968,27),(5280,30),(5436,27),(6148,29)\right\}\]
		\item ruled out by Theorem \ref{cometricbnds} $(v)$ and $(iii)$,
		\[\left\{(8432,31),(9984,32)\right\}\]
		\item ruled out by Theorem \ref{cometricbnds} $(v)$, $(iii)$, and $(ii)$
		\[\left\{(594,9),(7776,27),(8478,27),(9984,24)\right\}\]
		
	\end{itemize}
\end{itemize}
\subsection{$Q$-bipartite Association Schemes}
We conclude this section by proving $Q$-bipartite analogues of Theorem \ref{degreebound}, Corollary \ref{maxlambda}, and Theorem \ref{cometricbnds}. We begin by proving an important theorem concerning the eigenvalues $\theta_{\ell i}$ as described in Theorem \ref{schoen-as}.
\begin{thm}\label{Qbipeig}
	Let $(X,\cR)$ be a $Q$-bipartite association scheme with cometric ordering $E_0,E_1,\dots,E_d$. Define $\theta_{\ell,j}$ for $0\leq j\leq d$ and $\ell\geq 0$ so that
	\[G_\ell^m\circ\left(\frac{\vert X\vert}{m}E_1\right) = \sum_{j=0}^d\theta_{\ell,j}E_j.\]
	Then $\theta_{\ell,j} = 0$ whenever $\ell+j\notin2\bbZ$.
\end{thm}
\begin{proof}
	We prove this by induction. First, note that $\theta_{0,j} = \vert X\vert\delta_{0j}$ and thus $\theta_{0,j} = 0$ whenever $j\notin2\bbZ$. Now let $\ell\in\mathbb{Z}$ be given so that $\theta_{\ell,j} = 0$ whenever $\ell+j\notin 2\bbZ$ and consider
	\[\theta_{\ell+1,j}= \frac{(2\ell+m)(c_{j}^*\theta_{\ell,j-1} +a_i^*\theta_{\ell,j}+b_{j}^*\theta_{\ell,j+1}) - (\ell)m\theta_{\ell-2,j}}{m(\ell+m-2)}.\]
	If $(\ell+1)+j\notin2\bbZ$ then $\ell+(j-1),\ell+(j+1),(\ell-1)+j\notin2\bbZ$ and thus by our induction hypothesis,
	\[\theta_{\ell+1,j}= \frac{(2\ell+m)(a_i^*\theta_{\ell,j})}{m(\ell+m-2)}.\]
	However since $a_1^*=0$ for $Q$-bipartite schemes, we have $\theta_{\ell+1,j} = 0$.
\end{proof}
This theorem tells us that approximately half of the eigenvalues $\theta_{\ell,j}$ will be zero for a $Q$-bipartite scheme. This information allows us to recast many of the previous theorems seen in this section for this case.  We first consider Theorem $\ref{degreebound}$, following much of the same proof to prove the following theorem.

\begin{thm}\label{Qbipdegbnd}
	Suppose we have a feasible parameter set for a $Q$-bipartite association scheme with first and second eigenmatrices $P$ and $Q$ where the relations are ordered naturally. Define $\lambda_j:=\frac{Q_{j,1}}{m_1}$ and $k_j = P_{0,j}$ for $0\leq j\leq d$. Define $\gamma_{\ell,j} = \begin{cases}
	\lambda_j^2 & \text{ if }(1+\mu_\ell)^2\lambda_j^2\geq 4\mu_\ell\\
	\mu_\ell & \text{ if }(1+\mu_\ell)^2\lambda_j^2< 4\mu_\ell
	\end{cases}$ where $\mu_\ell = \frac{\ell-1}{\ell+Q_{0,i}-3}$. Let $\ell^*$ to be the smallest integer such that
	\[\sum_{j=1}^d \left(\prod_{\ell=2}^{\ell^*+1}\gamma_{\ell,j}\right)k_j(1+\lambda_j^2)\leq\frac{4}{\vert X\vert}.\]
	Then the requirements $\theta_{\ell,i}\geq 0$ for $0\leq i\leq d$ as defined in Theorem \ref{schoen-as} are implied by FC1 for degrees $\ell\geq \ell^*$.
\end{thm}
\begin{proof}
	Let $L_1^*$ be the Krein matrix of our parameter set. Define $M = \frac{1}{m_1}\sqrt{\Delta_m}L_1^*\sqrt{\Delta_m}^{-1}$. As with in Section \ref{proof}, let
	\begin{equation*}
	\vec{y}_\ell = T_\ell\vec{y}_{\ell-1} \qquad \ell\geq 2
	\end{equation*}
	with
	\begin{equation*}\mu_\ell = \frac{\ell-1}{\ell+m-3};\qquad \vec{y}_1 = \left[\begin{array}{c}
	\frac{1}{\sqrt{m}}\vec{e}_1\\\hdashline[2pt/2pt]
	\vec{e}_0
	\end{array}\right];\qquad T_\ell = \left[\begin{array}{>{\centering\arraybackslash}p{3cm};{2pt/2pt}>{\centering\arraybackslash}p{3cm}}
	$(1+\mu_\ell)M$ & $-\mu_\ell I$\\\hdashline[2pt/2pt]
	$I$ & $0$
	\end{array}\right].\end{equation*}
	Further define $B_j = \text{span}\left(\left[\begin{array}{c}
	\vec{p}_j\\\hdashline[2pt/2pt]
	\vec{0}
	\end{array}\right],\left[\begin{array}{c}
	\vec{0}\\\hdashline[2pt/2pt]
	\vec{p}_j
	\end{array}\right]\right)$ for $0\leq j\leq d$ where $\vec{p}_j$ is the $j^\text{th}$ column of $\sqrt{\Delta_m}P$.
	Then Lemma \ref{normbound} tells us that 
	\[\text{proj}_{B_j}(\vec{y}_1) = \frac{1}{\vert X\vert}\left[\begin{array}{c}
	\lambda_j\vec{p}_j\\\hdashline[2pt/2pt]
	\vec{p}_j
	\end{array}\right];\qquad\left\vert\left\vert \left(\prod_{\ell=2}^{\ell^*} T_\ell\right) \text{proj}_{B_j}(\vec{y}_1)\right\vert\right\vert_2^2\leq \left(\prod_{\ell=2}^{\ell^*}\gamma_{\ell,j}\right)\left\vert\left\vert\text{proj}_{B_j}(\vec{y}_1)\right\vert\right\vert_2^2.\]
	For a $Q$-bipartite scheme, the first and last column of $\sqrt{\Delta}P$ are given by 
	\[\vec{p}_0 = \left[1,\sqrt{m},\dots,\sqrt{m_{d-1}},1\right]^T,\qquad \vec{p}_d = \left[1,-\sqrt{m},\dots,(-1)^{d-1}\sqrt{m_{d-1}},(-1)^d\right]^T\] with $\lambda_0 = -\lambda_d = 1$. Noting that the roots of the polynomial $x^2-(1+\mu_\ell)(\pm 1)x + \mu_\ell$ are $\pm1$ and $\mu_\ell$, we find that both $\text{proj}_{B_0}(\vec{y}_1)$ and $\text{proj}_{B_d}(\vec{y}_1)$ are eigenvectors of $T_\ell$ for all $\ell\geq 2$. Therefore
	\[ \text{proj}_{B_0}(\vec{y}_{\ell^*}) = \text{proj}_{B_0}(\vec{y}_1);\qquad \text{proj}_{B_d}(\vec{y}_{\ell^*}) = \left(-1\right)^{\ell^*-1}\text{proj}_{B_0}(\vec{y}_1).\]
	For a vector $\vec{v}$ of length $d+1$, we refer to the entries $v_0,v_2,v_4,\dots,v_{2\left\lfloor\frac{d}{2}\right\rfloor}$ as the \textit{even part of} $\vec{v}$ and likewise the entries $v_1,v_3,\dots,v_{2\left\lceil\frac{d}{2}\right\rceil-1}$ as the \textit{odd part of} $\vec{v}$. Further, for a vector $\vec{y}$ of length $2d+2$, define the \textit{top half of} $\vec{y}$ to be the first $d+1$ entries and the \textit{bottom half of} $\vec{y}$ to be the last $d+1$ entries. Then we have the following four statements
	\begin{itemize}
		\item For even $\ell$,
		\begin{itemize}
			\item all entries in the odd part of the top half of $\text{proj}_{B_0\cup B_d}(\vec{y}_\ell)$ are 0;
			\item all entries in the even part of the bottom half of $\text{proj}_{B_0\cup B_d}(\vec{y}_\ell)$ are 0.
		\end{itemize}
		\item For odd $\ell$,
		\begin{itemize}
			\item all entries in the even part of the top half of $\text{proj}_{B_0\cup B_d}(\vec{y}_\ell)$ are 0;
			\item all entries in the odd part of the bottom half of $\text{proj}_{B_0\cup B_d}(\vec{y}_\ell)$ are 0.
		\end{itemize}
	\end{itemize}
	Similarly Theorem \ref{Qbipeig} shows that the same is true for $y_\ell$, that is
	\begin{itemize}
		\item For even $\ell$,
		\begin{itemize}
			\item all entries in the odd part of the top half of $y_\ell$ are 0;
			\item all entries in the even part of the bottom half of $y_\ell$ are 0.
		\end{itemize}
		\item For odd $\ell$,
		\begin{itemize}
			\item all entries in the even part of the top half of $y_\ell$ are 0;
			\item all entries in the odd part of the bottom half of $y_\ell$ are 0.
		\end{itemize}
	\end{itemize}
	We find also that $\text{proj}_{B_0}(\vec{y}_\ell) + \text{proj}_{B_d}(\vec{y}_\ell)$ is non-zero except in the entries listed above. This implies the sum of the remaining projections must follow the same pattern, permitting non-zero values only when $\text{proj}_{B_0}\left(y_\ell\right)+\text{proj}_{B_d}\left(y_\ell\right)$ is also non-zero. Since the smallest remaining entry of $\text{proj}_{B_0}(\vec{y}_\ell) + \text{proj}_{B_d}(\vec{y}_\ell)$ is $\frac{2}{\vert X\vert}$, we have that
	\[\left\vert\left\vert \sum_{j=1}^{d-1}\left(\prod_{\ell=2}^{\ell^*+1}T_\ell\right)\text{proj}_{B_j}(\vec{y}_1)\right\vert\right\vert^2_2 \leq\frac{4}{\vert X\vert^2}\]
	implies $y_{\ell^*+1}$ has no negative entries. Following the reasoning from before, we note that if $y_{\ell^*}$ has a negative value, it must appear in the bottom half, thus $y_{\ell^*-1}$ must have a negative value and it is sufficient to check the first $\ell^*-1$ degrees.	
\end{proof}
\begin{cor}\label{Qbipuppbnd}
	Suppose we have a feasible parameter set for a $Q$-bipartite association scheme with relations ordered naturally. Define $\lambda_1:=\nicefrac{Q_{1,1}}{m_1}$ and let $\lambda^*\geq\vert\lambda_1\vert$ be given. Then for
	\[\ell^*=\left\lceil\frac{\ln\left[\left(1+\lambda_1^2\right)\vert X\vert\left(\vert X\vert-2\right)\right]-\ln(4)}{-2\ln\left(\lambda^*\right)}\right\rceil,\]
	if $\left\vert\lambda^*\right\vert^2\geq \frac{\ell^*}{\ell^*+m_1-2}$ then $\theta_{\ell,j}\geq 0$ is implied by FC1 for $\ell\geq \ell^*$ and $0\leq j\leq d$.
\end{cor}
\begin{proof}
	First note that $\vert\lambda_1\vert\geq \vert\lambda_j\vert$ for $1\leq j\leq d-1$ due to the natural ordering and bipartite properties. Therefore, as long as $\left\vert \lambda^*\right\vert^2$ is greater than both $\mu_{\ell}$ for $2\leq\ell\leq x$ and $\vert\lambda_1\vert^2$,
	\[\sum_{j=1}^{d-1} v_j(1+\lambda_j^2)\left(\prod_{\ell=2}^x \gamma_{x,j}\right)\leq(\lambda^*)^{2x-2}(1+\lambda_1^2)\sum_{j=1}^{d-1} v_j =(\lambda^*)^{2x-2}(1+\lambda_1^2)(\vert X\vert -2). \]
	Solving 
	\[(\lambda^*)^{2x-2}(1+\lambda_1^2)(\vert X\vert -2)\leq\frac{4}{\vert X\vert}\]
	for $x$ gives
	\[x\geq\frac{\ln\left[(1+\lambda_1^2)\vert X\vert(\vert X\vert-2)\right]-\ln(4)}{-2\ln(\lambda^*)}+1.\]
	Thus defining $\ell^* = \left\lceil\frac{\ln\left[(1+(\lambda_1)^2)\vert X\vert(\vert X\vert-2)\right]-\ln(4)}{-2\ln(\lambda^*)}\right\rceil$ gives that $\ell^*+1$ is the smallest integer for which our inequality holds. Then, as long as $\vert\lambda^*\vert^2\geq \mu_{\ell^*+1}$, we may use Theorem \ref{Qbipdegbnd} to give our result.
\end{proof}
Finally, we use our $Q$-bipartite property to simplify the expressions in Theorem \ref{cometricbnds}.
\begin{cor}\label{Qbipbnds}
	Suppose we have a feasible parameter set for a $Q$-bipartite association scheme with Krein array $\left\{m,b^*_1,\dots,b^*_{d-1};1,c_2^*\dots,c^*_{d}\right\}$. Then the scheme is realizable only if each of the following hold:
	\begin{enumerate}[label=(\roman*)]
		\item $b_1^*c_2^* \geq\frac{2m(m-1)}{m+2},$
		\item $c_2q^2_{22}\geq \frac{4m(m-2)}{m+4},$
		\item $\frac{6m(m-1)(m-4)}{(m+4)(m+6)} + \frac{b_1^*c_2^*c_2^*q_{22}^2}{m}\geq \frac{b_1^*c_2^*(7m-18)}{m+6},$
		\item $\sum_{i=1}^3b_i^*c_{i+1}^*\leq \frac{3(3m-2)}{m+6},$
		\item $\frac{16m(m-1)}{(m+4)b_1^*c_2^*} + \frac{c_2^*q_{22}^2(m+8)}{(m-2)m}\geq 12.$
	\end{enumerate}
\end{cor}
\begin{proof}
	Consider Theorem \ref{cometricbnds} with the added constraint that $a_i^* = 0$ for $0\leq i\leq d$.
\end{proof}
\subsection*{Example}
Consider the feasible parameter set with first and second eigenmatrices 
\[P = \left[\begin{array}{rrrrr}
1 & 1116 & 7750 &1116 &1\\
1 &186& 0 &-186& -1\\
1 &24& -50& 24& 1\\
1 &-6& 0 &6 &-1\\
1 &-36& 70 &-36& 1\\
\end{array}\right],\qquad Q = \left[\begin{array}{rrrrr}
1 &156& 2976& 4836 &2015\\
1 &26& 64 &-26& -65\\
1 &0 &\nicefrac{-96}{5} &0 &\nicefrac{91}{5}\\
1 &-26& 64 &26& -65\\
1 &-156& 2976& -4836& 2015
\end{array}\right].\]
If realizable, the association scheme with this parameter set would be a 4-class $Q$-bipartite scheme. Defining $\lambda^*:=\sqrt{\mu_6} = \sqrt{\frac{5}{159}}$ and noting that $\lambda_1 = \frac{Q_{11}}{m} = \frac{1}{6}$, we have
\[\left\lceil\frac{\ln\left[\left(1+\left(\lambda_1\right)^2\right)\vert X\vert\left(\vert X\vert-2\right)\right]-\ln(4)}{-2\ln\left(\lambda^*\right)}\right\rceil = 5.\]
Since $\left\vert\lambda^*\right\vert^2 = \mu_6 = \frac{4}{158}>\frac{1}{36} = \left\vert \lambda_1\right\vert^2$, we may use Corollary \ref{Qbipuppbnd} to show that $\theta_{\ell,j}\geq 0$ is vacuous for this parameter set for $\ell\geq 5$. We list the remaining eigenvalues below
\[\left[\begin{array}{ccccc}
9984 & 0 & 0 & 0 & 2.61\\
0 & 64 & 0 & 2.56 & 0\\
0 & 0 & 3.36 & 0 & 1.99\\
0 & 0 & 0 & 1.98& 0\\
0 & 0 & 0 & 0 & 2.02
\end{array}\right]\]
Since all eigenvalues are non-negative, this parameter set is still feasible. We will see many more examples such as this in Chapter \ref{4classbip}, many of which will be ruled out.


