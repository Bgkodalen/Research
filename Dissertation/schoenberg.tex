\chapter{Polynomial ring of Association schemes}\label{schoenberg}
Chapter $\ref{psdcone}$ examined a particular set of matrices in the Bose-Mesner algebra of an association scheme which gave us Gram matrices of finite sets $X\subset \mathbb{S}^{m-1}$ for some fixed positive integer $m$. In particular, we found that the existence of any association scheme implies the existence of sets of vectors with very few possible inner products. While we may use this correlation to create new spherical $t$-distance sets anytime we have an association scheme, we may also use this implication to rule out possible parameter sets based on the properties of the resultant vector sets. For instance, Delsarte et al.\ in \cite{Delsarte1975} found bounds on the size of any $t$-distance set based solely on the dimension of the ambient space and the inner products allowed between vectors. Later, in \cite{Delsarte1977}, they were also able to prove a $t$-distance set is a spherical design if and only if the first $s$ Gegenbauer polynomials summed over the inner products give zero as a result. This characterization of spherical designs allowed Suda \cite{Suda2011} to characterize when a the first idempotent in a $Q$-polynomial ordering would result in a spherical design. Many of these results are based around a family of single-variable polynomials known as the Gegenbauer polynomials, and a result of Sch\"{o}nberg \cite{Schoenberg1942} which implies that each Gegenbauer polynomial will result in a positive semi-definite matrix when applied to a Gram matrix elementwise.\par
In this chapter, we will define the Gegenbauer polynomials and review relevant definitions and theorems. We will then use a consequence of Sch\"{o}nberg's theorem to provide a general constraint on the minimal idempotents of association schemes. We then leverage properties of association schemes to derive parameter restrictions on a general association scheme, noting where these restrictions become non-trivial. We then examine these restrictions more closely in the setting of $Q$-polynomial association schemes where we give three non-trivial constraints. Finally, we will give examples of new parameter sets which are ruled out by these constraints and consider the case of $4$-class $Q$-bipartite association schemes where one constraint in particular greatly restricts the feasible parameter sets. Below is a list of main theorems which will appear in this chapter.
\begin{restatable*}{thm}{schAS}\label{schoen-as}
	Let $(X,\mathcal{R})$ be an association scheme with minimal idempotents $E_0,\dots,E_d$ and krein matrices $L_0^*,\dots,L_d^*$. Let $0\leq i\leq d$ be given and define $m_i:=\text{rank}\left(E_i\right)$. Let $\text{Ann}_{i}(t) := \prod_{a\in \sQ}(t-a)$ where $\sQ = \left\{Q_{ji}\right\}_{j=0,\dots,d}$. Then for any choice of $k>0$, there exists non-negative constants $\theta_j$ for $0\leq j\leq d$ so that
	\begin{equation}\label{entrywiseGeg}
	Q_k^{m_i}\circ\left(\frac{\vert X\vert}{m_i}E_i\right) = \sum_j \theta_j E_j
	\end{equation}
	\begin{equation}\label{LGeg}
	Q_k^{m_i}\left(\frac{1}{m_i}L_i^*\right) = \frac{1}{\vert X\vert}\sum_j \theta_j L_j^*\\
	\end{equation}
	\begin{equation}\label{redGeg}
	f^{m_i}_k\left(\frac{1}{m_i}L_i^*\right) = \frac{1}{\vert X\vert}\sum_j \theta_j L_j^*\\
	\end{equation}
	where $f^{m_i}_k\in\left[Q_k^{m_i}\right]_{Ann_i}$. In each case, each $\theta_j$ is an eigenvalue of the matrix on the left with multiplicity (at least) $m_j$. Further, $c_j$ is nonzero only if $E_j$ is contained in the subalgebra generated by $E_i$ using entrywise products.
\end{restatable*}
\begin{restatable*}{thm}{degbnd}
	\label{degreebound}
		We may bound the degree of Gegenbauer polynomials which give us nontrivial constraints using Rayleigh quotients.
\end{restatable*}
\section{Gegenbauer Polynomials}
In this section we will use polynomial rings and quotient rings, thus we begin this section with a brief review of the topic, referring to \cite{Gallian}(TODO: Bad reference here) for a more complete introduction. In all that follows let $m$ be a fixed positive integer and define $\scR:=\bbR[x_1,\dots,x_m]$. A \emph{monomial} is defined as a (possibly empty) product of the variables $x_1,\dots,x_m$ and given a monomial $t =\prod_{i=1}^{m}x_i^{d_i}$ ($d_i\in \bbZ^+$), the \emph{degree} of $t$ is defined as $\text{deg}(t) = \sum_i d_i$. A polynomial $f\in\scR$ may be represented uniquely as a (finite) linear combination of distinct monomials $f =\sum_i\alpha_it_i$ and $\text{deg}(f) = \max\left\{\text{deg}(t_i)\right\}$. For each variable $x_j$, we define the \emph{derivative with respect to $x_j$} of a monomial as $\frac{\partial}{\partial x_j}t = d_jx_j^{d_j-1}\prod_{i\neq j}x_i^{d_i}$ and extend the definition linearly for any polynomial in $\scR$. For $f\in \scR$, $f$ is \emph{homogeneous} if there exists some constant $d\in\bbZ^+$ such that $\text{deg}(t)=d$ for every monomial $t$ in $f$. Further, $f$ is \emph{harmonic} if $\Delta f = \sum_i \left(\frac{\partial}{\partial x_i}\circ\frac{\partial}{\partial x_i}\right)\left(f\right) = 0$.\par
Let $f\in\scR$ be given and define the ideal of $f$ as $(f) = \left\{gf:g\in\scR\right\}$. We then define equivalence classes $[g]_f = \left\{h\in\scR: g-h\in(f)\right\}$. The quotient ring $\nicefrac{\scR}{(f)}$ is given as the set of equivalence classes $\left\{[g]_f:g\in\scR\right\}$. We will often suppress the subscript if it is clear from the context. Let $S^{m-1}\subset \bbR^m$ be the $m-1$ dimensional sphere, we define the set of polynomials on the sphere as
\[\text{Pol}(S^{m-1}):= \nicefrac{\scR}{\left(1-\sum_ix_i^2\right)}.\]
We say a polynomial $f\in\scR$ is \emph{harmonic on the sphere} if there exists a harmonic polynomial $g\in[f]$. Similarly, a polynomial is \emph{homogeneous on the sphere} if there exists a homogeneous polynomial $g\in[f]$. Finally, we say a polynomial $f\in\bbR$ is \emph{zonal} if there exists a vector $a\in \bbR^m$ and a single-variable polynomial $g(t)\in\bbR[t]$ such that $f(x) = g(\left<a,x\right>)$ for all $x\in S^{m-1}$. Note that since $h\in \left(1-\sum_ix_i^2\right)$ implies $h(x) = 0$ for all $x\in S^{m-1}$, this requirement is independent of the representative chosen from the equivalence class.\par
We now introduce a particular set of polynomials arising from the context of spherical harmonics polynomials. The Gegenbauer polynomials in dimension $m$ are defined using the three-term recurrence:
\begin{equation}\label{recurrence}
Q_k^m(t) = \frac{(2k+m-4)tQ_{k-1}(t) - (k-1)Q_{k-2}(t)}{k+m-3} \qquad k\geq 2,
\end{equation}
\begin{equation*}
Q^m_0(t) = 1\qquad Q^m_1(t) = t.
\end{equation*}
We use these initial polynomials so that $Q^m_k(1) = 1$ for all $k\geq 0$. We will suppress the superscript $m$ anytime this is clear in the context. The first six Gegenbauer polynomials are as follows,
\[\begin{aligned}
&Q_0(t)=1,\qquad
Q_1(t)=t,\qquad
Q_2(t)=\frac{mt^2 - 1}{m-1},\qquad
Q_3(t)=\frac{(m+2)t^3 - 3t}{m-1},\qquad\\
Q_4(t)=&\frac{(m+4)(m+2)t^4 - 6(m+2)t^2+3}{m^2-1},\qquad
Q_5(t)=\frac{(m+6)(m+4)t^5-10(m+4)t^3+15t}{m^2-1}\\
\end{aligned}\]\newpage
\begin{figure}[!h]
	\begin{center}
		\includegraphics[scale=.4]{gegenbauer_polynomials.PNG}
		\caption[Gegenbauer polynomials]{Gegenbauer polynomials with degree 1 through degree 5 with $m=10$.}\label{gegpic}
	\end{center}
\end{figure}
\begin{figure}[!h]
	\begin{center}
		\includegraphics[scale=.4]{roots.PNG}
		\caption[Roots of Gegenbauer polynomials]{Roots of the five Gegenbauer polynomials plotted in Figure \ref{gegpic}.}\label{rootpic}
	\end{center}
\end{figure}
\begin{thm}\label{gegprop}
	For each $m,i\in\bbZ^+$ and $a\in\bbR^m$, the Gegenbauer polynomial $Q_i^m\left(\left<a,x\right>\right)$ is zonal and both homogeneous and harmonic on the sphere.
\end{thm}
\begin{proof}
	The zonal condition is satisfied trivially. The other two conditions follow from $F^m_k(x)\in\left[Q_i^m(\left<a,x\right>)\right]$ for 
	\[F_k^m(x)= \left<x,x\right>^{\lfloor\frac{k+1}{2}\rfloor}Q_k^m\left(\frac{\left<a,x\right>}{\left<x,x\right>}\right).\]
\end{proof}
We note that, up to scaling and rotation of the sphere, $F_k^m(x)$ as defined above is the unique degree $k$ polynomial with all three of these properties. These polynomials have played an important role in understanding spherical $t$-distance sets as well as $t$-designs (\cite{Delsarte1977},\cite{Suda2011}). Many of these results come from considering a finite set of points on the sphere and a basis of the harmonic polynomials on the sphere with fixed degree. We then create vectors for each point in our set by evaluating each basis polynomial at those points. Taking inner products we may then use Theorem \ref{gegprop} to show that the resulting values must be equal to a Gegenbauer polynomial evaluated at the inner product of our two points. It should not be surprising that these polynomials were of interest before \cite{Delsarte1977}, in fact 
35 years earlier, Sch\"{o}nberg characterized positive definite functions on the sphere using these same polynomials. We will now consider this theorem and investigate the consequences as they pertain to association schemes.
\section{Sch\"{o}nberg's theorem}
Let $m$ be a fixed positive integer as before and let $X\subset S^{m-1}$ be a finite set of unit vectors. Let $G_X$ denote the Gram matrix of $X$, then $G_X$ is positive semi-definite ($G_X\succeq 0$). A function $f:[-1,1]\rightarrow\mathbb{R}$ is \textit{positive definite} if, for every such finite subset $X$, $f\circ(G_X)\succeq 0$.
\begin{thm}[Sch\"{o}nberg \cite{Schoenberg1942}]\label{schoenthm}
	Fix $m\in\mathbb{Z}^+$. A function $f:[-1,1]\rightarrow\mathbb{R}$ is positive definite on $S^{m-1}$ if and only if $f(t) = \sum_{i} c_iQ_k^m(t)$ for non-negative constants $c_i$.\qed
\end{thm}
In particular, this means that $Q_k^m(t)$ is a positive definite function for any choice of $m$ and $k$. This leads theorem \ref{schoen-as}:
\schAS
\begin{comment}
\begin{thm}\label{schoen-as}
	Let $(X,\mathcal{R})$ be an association scheme with minimal idempotents $E_0,\dots,E_d$ and krein matrices $L_0^*,\dots,L_d^*$. Let $0\leq i\leq d$ be given and define $m_i:=\text{rank}\left(E_i\right)$. Let $\text{Ann}_{i}(t) := \prod_{a\in \sQ}(t-a)$ where $\sQ = \left\{Q_{ji}\right\}_{j=0,\dots,d}$. Then for any choice of $k>0$, there exists non-negative constants $\theta_j$ for $0\leq j\leq d$ so that
	\begin{equation}\label{entrywiseGeg}
	Q_k^{m_i}\circ\left(\frac{\vert X\vert}{m_i}E_i\right) = \sum_j \theta_j E_j
	\end{equation}
	\begin{equation}\label{LGeg}
	Q_k^{m_i}\left(\frac{1}{m_i}L_i^*\right) = \frac{1}{\vert X\vert}\sum_j \theta_j L_j^*\\
	\end{equation}
	\begin{equation}\label{redGeg}
	f^{m_i}_k\left(\frac{1}{m_i}L_i^*\right) = \frac{1}{\vert X\vert}\sum_j \theta_j L_j^*\\
	\end{equation}
	where $f^{m_i}_k\in\left[Q_k^{m_i}\right]_{Ann_i}$. In each case, each $\theta_j$ is an eigenvalue of the matrix on the left with multiplicity (at least) $m_j$. Further, $c_j$ is nonzero only if $E_j$ is contained in the subalgebra generated by $E_i$ using entrywise products.
\end{thm}
\end{comment}
\begin{proof}
	Recall that the Bose-Mesner algebra given by $\BMA =\text{span}\left\{E_0,\dots,E_d\right\}$ is closed under entrywise products. Then $Q_k^{m_i}\circ\left(\frac{\vert X\vert}{m_i}E_i\right)\in \BMA$ and we may write $Q_k^{m_i}\circ\left(\frac{\vert X\vert}{m_i}E_i\right) = \sum_j c_j E_j$ where each $c_j$ is the eigenvalue of $Q_k^{m_i}\circ\left(\frac{\vert X\vert}{m_i}E_i\right)$ in the eigenspace given by the idempotent $E_j$. Now recall there exists an algebra isomorphism $\phi^*:\BMA\rightarrow\bbL$ via $\phi^*\left(E_i\right)=\frac{1}{\vert X\vert}L_i^*$ extended linearly with the property that $\phi^*(E_i\circ E_j) = \phi^*(E_i)\phi^*(E_j)$. Applying $\phi^*$ to both sides of equation \ref{entrywiseGeg} gives equation \ref{LGeg}. Now, since $Ann_i$ is defined so that $Ann_i\circ\left(\frac{\vert X\vert}{m_i}E_i\right) = 0$, we again use $\phi^*$ to find that $Ann_i\left(\frac{1}{m_i}L_i^*\right) = 0$. Thus any polynomial $f_k^{m_i}$ for which $f_k^{m_i}(x) - Q_k^{m_i}(x)\in\left(Ann_i\right)$ will satisfy $f_k^{m_i}\left(\frac{1}{m_i}L_i^*\right) = Q_k^{m_i}\left(\frac{1}{m_i}L_i^*\right)$, giving equation \ref{redGeg}. Finally, since $E_i$ is an idempotent matrix with constant main diagonal entries given by $\frac{1}{\vert X\vert}Q_{0i} = \frac{m_i}{\vert X\vert}$, we know that $\frac{\vert X\vert}{m_i}E_i$ is the Gram matrix of a set of points in $S^{m_i-1}$. Therefore, Theorem~\ref{schoenthm} tells us that $Q_k^{m_i}\circ\left(\frac{\vert X\vert}{m_i}E_i\right)$ must be positive semidefinite.
\end{proof}
While each degree $k$ gives a new restriction on the parameters of our association scheme, we expect that many of these conditions will be vacuous. Thus we examine these equations closely and will show that we may bound the degree of non-trivial restrictions based on the second largest entry of the matrix $E_i$.
\subsection{Proof of Theorem \ref{degreebound}}
Recall from \ref{kreinidentities} that for each $0\leq i\leq d$, $q^j_{j0} = \delta_{i,j}$. Therefore, let $\vec{c}_k$ be the first column of the matrix $Q_{k}^{m_i}\left(\frac{1}{m_i}L_i^*\right)$ and using equation \eqref{LGeg} with equation \eqref{recurrence} we have,
\begin{equation}\label{crec}
\vec{c}_k = \frac{(2k+m_i-4)\frac{1}{m_i}L_i^*\vec{c}_{k-1} - (k-1)\vec{c}_{k-2}}{k+m-3} \qquad k\geq 2,
\end{equation}
where the entries of $\vert X\vert \vec{c}_k$ are the eigenvalues of $Q_{k}^{m_i}\left(\frac{\vert X\vert}{m_i}E_i\right)$. Since $Q_0^m\left(\frac{\vert X\vert}{m_i}E_i\right) = J$ and $Q_1^m\left(\frac{\vert X\vert}{m_i}E_i\right) = \frac{\vert X\vert}{m_i}E_i$, we know that
\begin{equation*}
\vec{c}_0 = \vec{e}_0\qquad \vec{c}_1 = \frac{1}{m_i}\vec{e}_i
\end{equation*}
where $\vec{e}_i$ is the $i^\text{th}$ standard basis vector. While these vectors have a convenient relation with the matrices in equation \eqref{LGeg}, we will find it convenient to instead consider the vectors $\vec{b}_k = \sqrt{\Delta_m}\vec{c}_k$ where $\sqrt{\Delta_m}$ is the diagonal matrix with $i^\text{th}$ diagonal entry $\sqrt{m_i}$. This transformation turns our recurrence relation into:
\begin{equation}\label{brec}
\vec{b}_k = \frac{(2k+m_i-4)M\vec{b}_{k-1} - (k-1)\vec{b}_{k-2}}{k+m-3} \qquad k\geq 2,
\end{equation}
where $M = \frac{1}{m_i}\sqrt{\Delta_m}L_i^*\left(\sqrt{\Delta_m}\right)^{-1}$. We also have the initial conditions
\begin{equation*}
\vec{b}_0 = \vec{e}_0\qquad \vec{b}_1 = \frac{1}{\sqrt{m_i}}\vec{e}_i.
\end{equation*}
Before moving on, we prove a lemma concerning $M$ which was the motivation for making this transformation.
\begin{lem}\label{Mmat}
	Let $M = \frac{1}{m_i}\sqrt{\Delta_m}L_i^*\left(\sqrt{\Delta_m}\right)^{-1}$. Then the vectors $\left\{\vec{p}_0,\vec{p}_1,\dots,\vec{p}_d\right\}$ with
	\[p_j = \left[\begin{array}{c}
	P_{0j}\\
	\sqrt{m_1}P_{1j}\\
	\vdots\\
	\sqrt{m_d}P_{dj}\\
	\end{array}\right]\]
	serve as an orthogonal set of eigenvectors for $M$ with corresponding eigenvalues $\frac{Q_{0i}}{m_i},\frac{Q_{1i}}{m_i},\dots,\frac{Q_{di}}{m_i}$.
\end{lem}
\begin{proof}
First recall that the eigenvectors of $L_i^*$ are the columns of $P$ with eigenvalues $Q_{0i},Q_{1i},\dots,Q_{di}$. Since we are conjugating by an invertible matrix, we have the eigenvectors of $M$ are the columns of $\sqrt{\Delta_m}P$ with the eigenvalues scaled by our constant $\frac{1}{m_i}$. Now, using our orthogonality relations, we have that $\Delta_m P = Q^T \Delta_v$ and $PQ = \vert X\vert I$. Therefore
\[\left(\sqrt{\Delta_m}P\right)^T\left(\sqrt{\Delta_m}P\right) = P^T\Delta_mP = P^TQ^T\Delta_v = \vert X\vert\Delta_v.\]
\end{proof}
Now that we have an orthogonal set of eigenvectors, we define a final set of vectors for which the recurrence relation becomes linear. Let 
\begin{equation}\label{tkdef}\mu_k = \frac{k-1}{k+m-3};\qquad \vec{y}_k = \left[\begin{array}{c}
\vec{b}_{k}\\\hdashline[2pt/2pt]
\vec{b}_{k-1}
\end{array}\right];\qquad T_k = \left[\begin{array}{>{\centering\arraybackslash}p{3cm};{2pt/2pt}>{\centering\arraybackslash}p{3cm}}
 $(1+\mu_k)M$ & $-\mu_k I$\\\hdashline[2pt/2pt]
$I$ & $0$
\end{array}\right].\end{equation}
Then we have
\begin{equation}\label{yrec}
	\vec{y}_k = T_k\vec{y}_{k-1}.
\end{equation}
While $T_k$ will change as we iterate through $k$, we find some common properties among the eigenvalues and eigenvectors of $T_k$ for all values of $k$. We will prove a few lemmas which work towards Theorem \ref{degreebound}.
\begin{lem}\label{Tkeig}
	Let $(\lambda,\vec{v})$ be an eigenpair of $M$. Define $\left\{\eta_\lambda^+,\eta_\lambda^-\right\}$ be the two roots of the quadratic equation $\eta^2-(1+\mu_k)\lambda\eta +\mu_k=0$. If $\eta_\lambda^+\neq\eta_\lambda^-$ then both
	$\left(\eta_\lambda^+,\left[\begin{array}{c}
	\eta_\lambda^+\vec{v}\\\hdashline[2pt/2pt]
	\vec{v}
	\end{array}\right]\right)$ and $ \left(\eta_\lambda^+,\left[\begin{array}{c}
	\eta_\lambda^+\vec{v}\\\hdashline[2pt/2pt]
	\vec{v}
	\end{array}\right]\right)$
	are eigenpairs of $T_k$. If instead $\eta_\lambda^+=\eta_\lambda^-$ then $\left(\eta_\lambda^+,\left[\begin{array}{c}
	\eta_\lambda^+\vec{v}\\\hdashline[2pt/2pt]
	\vec{v}
	\end{array}\right]\right)$ is still an eigenpair with a generalized eigenvector $\left(\eta_\lambda^+,\left[\begin{array}{c}
		\vec{v}\\\hdashline[2pt/2pt]
		\vec{0}
	\end{array}\right]\right)$
\end{lem}
\begin{proof}
	Let $M \vec{v} = \lambda\vec{v}$ and let $\eta$ be given so that $\eta^2-(1+\mu_k)\lambda\eta +\mu_k=0$. Then,
	\[T_k\left[\begin{array}{c}
	\eta \vec{v}\\\hdashline[2pt/2pt]
	\vec{v}
	\end{array}\right] = \left[\begin{array}{c}
	(1+\mu_k)M(\eta \vec{v}) - \mu \vec{v}\\\hdashline[2pt/2pt]
	\eta \vec{v}
	\end{array}\right] = \left[\begin{array}{c}
	\left((1+\mu_k)\lambda\eta - \mu_k\right) \vec{v}\\\hdashline[2pt/2pt]
	\eta \vec{v}
	\end{array}\right] =  \left[\begin{array}{c}
	\eta^2 \vec{v}\\\hdashline[2pt/2pt]
	\eta \vec{v}
	\end{array}\right].\]
	Since our only requirement on $\eta$ was that it satisfied our quadratic equation, both roots will result in $T_k\left[\begin{array}{c}
	\eta \vec{v}\\\hdashline[2pt/2pt]
	\vec{v}
	\end{array}\right] =  \eta\left[\begin{array}{c}
	\eta \vec{v}\\\hdashline[2pt/2pt]
	 \vec{v}
	\end{array}\right].$ If we have two distinct roots $(\eta_\lambda^+\neq \eta_\lambda^-)$ then the vectors $\left[\begin{array}{c}
	\eta_\lambda^+ \vec{v}\\\hdashline[2pt/2pt]
	\vec{v}
	\end{array}\right]$ and $\left[\begin{array}{c}
		\eta_\lambda^- \vec{v}\\\hdashline[2pt/2pt]
		\vec{v}
	\end{array}\right]$ are linearly independent and we have two distinct eigenvectors. If instead we find that $\eta^2-(1+\mu_k)\lambda\eta +\mu_k=0$ has a double root, then $(1+\mu_k)\lambda^2-4\mu_k=0$ and thus $\eta = \frac{(1+\mu_k)\lambda}{2}$. In this case, note that
	\[T_k\left[\begin{array}{c}
	\vec{v}\\\hdashline[2pt/2pt]
	\vec{0}
	\end{array}\right] = \left[\begin{array}{c}
	(1+\mu_k)\frac{1}{m_i}L_i^*( \vec{v})\\\hdashline[2pt/2pt]
	\vec{v}
	\end{array}\right]= \left[\begin{array}{c}
	(1+\mu_k)\lambda\vec{v}\\\hdashline[2pt/2pt]
	\vec{v}
	\end{array}\right] = \left[\begin{array}{c}
	\eta \vec{v}\\\hdashline[2pt/2pt]
	\vec{0}
	\end{array}\right]+\left[\begin{array}{c}
	\eta \vec{v}\\\hdashline[2pt/2pt]
	\vec{v}
	\end{array}\right].\]
	Thus $(T_k-\eta I)\left[\begin{array}{c}
	\vec{v}\\\hdashline[2pt/2pt]
	\vec{0}
	\end{array}\right] = \left[\begin{array}{c}
	\eta \vec{v}\\\hdashline[2pt/2pt]
	\vec{v}
	\end{array}\right]$ giving us that $\left[\begin{array}{c}
	\vec{v}\\\hdashline[2pt/2pt]
	\vec{0}
	\end{array}\right]$ is a generalized eigenvector. Note that the restriction $(1+\mu_k)\lambda^2-4\mu_k=0$ is quite strong and requires that $k = \frac{\lambda^2(m-2)}{2\left(\pm\sqrt{1-\lambda^2}-(1-\lambda^2)\right)}+m-1$. Since $k$ is a positive integer, this means that $\frac{\lambda^2(m-2)}{2\left(\pm\sqrt{1-\lambda^2}-(1-\lambda^2)\right)}\in\bbZ$. Thus we can check ahead of time if this case will ever arise.
\end{proof}
Lemma \ref{Tkeig} gives a complete description of the eigenspaces of our transition matrix $T_k$ since we know $M$ is diagonalizable with orthogonal eigenvectors and thus the eigenvectors of $T_k$ may be split into pairs where vectors from distinct pairs are orthogonal to each other. Our next lemma examines one pair and bounds the action of $T_k$ on that subspace.
\begin{lem}
	Let $\left(\lambda,\vec{p}\right)$ be an eigenpair of $M$ and assume that $(1+\mu_k)^2\lambda^2-4\mu_k>0$ and thus $\eta^2-(1+\mu_k)\lambda\eta + \mu_k$ has two distinct real roots. Then, let $\left(\eta^+, \vec{v}^+\right)$ and $\left(\eta^-,v^-\right)$ be the two eigenpairs of $T_k$ arising from $\lambda$ as described in Lemma \ref{Tkeig}. Let $v = \left[\begin{array}{c}
	a\vec{p}\\\hdashline[2pt/2pt]
	b\vec{p}
	\end{array}\right]$. Then $\vert\frac{(1+\mu)\lambda}{2}\vert\leq \vert\frac{a}{b}\vert\leq\vert\lambda\vert$ implies $\vert\vert T_k v\vert\vert_2\leq \vert \lambda\vert\cdot\vert\vert v\vert\vert_2$.
\end{lem}
\begin{proof}
	We begin by noting that since our operator $T_k$ is linear, we may assume without loss of generality that $b=1$ and $\vert\vert\vec{p}\vert\vert_2 = 1$. Next, we know from Lemma \ref{Tkeig} that 
	\[v^+ = \left[\begin{array}{c}
	\eta^+ \vec{p}\\\hdashline[2pt/2pt]
	\vec{p}
	\end{array}\right];\qquad v^-=\left[\begin{array}{c}
	\eta^- \vec{p}\\\hdashline[2pt/2pt]
	\vec{p}
	\end{array}\right]\]
	and therefore $v = \left(\frac{\eta^--a}{\eta^--\eta^+}\right)v^+ + \left(\frac{a-\eta^+}{\eta^--\eta^+}\right)v^-$. We may then calculate $T_k v$ explicitly giving
	\[T_k v = \left(\frac{\eta^--a}{\eta^--\eta^+}\right)\eta^+v^+ + \left(\frac{a-\eta^+}{\eta^--\eta^+}\right)\eta^-v^- = \left[\begin{array}{c}
	\beta \vec{p}\\\hdashline[2pt/2pt]
	a\vec{p}
	\end{array}\right]\]
	where $\beta = \left(\frac{\eta^--a}{\eta^--\eta^+}\right)\left(\eta^+\right)^2 + \left(\frac{a-\eta^+}{\eta^--\eta^+}\right)\left(\eta^-\right)^2$. Thus,
	\[\begin{aligned}\vert\vert T_k v\vert\vert^2_2 &= \beta^2+a^2\\
	&=\frac{\left(\eta^--a\right)^2\left(\eta^+\right)^4 + \left(\eta^+\eta^-\right)^2\left(\eta^--a\right)\left(a-\eta^+\right) +\left(a-\eta^+\right)^2\left(\eta^-\right)^4}{\left(\eta^--\eta^+\right)^2}\\
	&=\left(\left(\eta^-+\eta^+\right)^2+1\right)a^2 - 2\eta^-\eta^+\left(\eta^-+\eta^+\right)a + \left(\eta^-\eta^+\right)^2\\
	&=\left((1+\mu)^2\lambda^2+1\right)a^2 - 2\mu(1+\mu)\lambda a + \mu^2\\
	&=\left(\left(\mu(2+\mu)\lambda^2+1\right)a^2 - 2\mu(1+\mu)\lambda a + (\mu^2-\lambda^2)\right)+\lambda^2(a^2+1)\end{aligned}\]
	Note however that we assumed $(1+\mu_k)^2\lambda^2-4\mu_k>0$ and thus
	\[\begin{aligned}\left(\mu(2+\mu)\lambda^2+1\right)a^2 - 2\mu(1+\mu)\lambda a + (\mu^2-\lambda^2)&\leq \left(\mu(2+\mu)\lambda^2\right)a^2 - 2\mu(1+\mu)\lambda a + \mu^2+(a^2-\lambda^2)\\
	&<0
	\end{aligned}\]
	for $0<\vert a\vert<\vert \lambda\vert$. (This is HW; pretty sure its true).\par
	One may show that
\end{proof}

Our next lemma bounds the spectrum of $T_k$ and describes where key eigenvalues arise.
\begin{lem}\ref{Tkspec} Let $k>0$ be given. Let $\lambda$ be an eigenvalue of $\frac{1}{m_i}L_i^*$ and assume $\eta$ solves the equation $\eta^2-(1+\mu_k)\lambda\eta +\mu_k=0$. If $\mu_k\leq\frac{2(1-\lambda^2)}{\lambda^2}$, then $\vert \eta\vert\leq \max\left\{\vert\lambda\vert,\mu_k\right\}$.
\end{lem}
\begin{proof}
	Let $\eta$ be given so that $\eta^2-(1+\mu_k)\lambda\eta +\mu_k=0$. Then $\eta = \frac{(1+\mu_k)\lambda \pm \sqrt{(1+\mu_k)^2\lambda^2 - 4\mu_k}}{2}$. We split the proof into three cases:
	\begin{itemize}
		\item First assume $(1+\mu_k)^2\lambda^2-4\mu_k<0$. Then our solutions $\eta = \frac{(1+\mu_k)\lambda\pm i\sqrt{4\mu_k-(1+\mu_k)^2\lambda^2}}{2}$ are complex. Therefore
		\[\vert \eta\vert^2 = \frac{(1+\mu_k)^2\lambda^2}{4}+ \mu_k - \frac{(1+\mu_k)^2\lambda^2}{4} = \mu_k.\]
		\item Now assume $(1+\mu_k)^2\lambda^2-4\mu_k>0$. Then our solutions $\eta = \frac{(1+\mu_k)\lambda\pm\sqrt{(1+\mu_k)^2\lambda^2-4\mu_k}}{2}$ are real and, using Cauchy Schwarz, we have
		\[\begin{aligned}\vert \eta\vert^2 = \left(\frac{(1+\mu_k)\lambda\pm\sqrt{(1+\mu_k)^2\lambda^2-4\mu_k}}{2}\right)^2&\leq2\left(\frac{(1+\mu_k)^2\lambda^2}{4}+\frac{(1+\mu_k)^2\lambda^2-4\mu_k}{4}\right)\\
		&=(1+\mu_k)^2\lambda^2 - 2\mu_k.\end{aligned}\]
		Assuming $\mu_k\leq \frac{2(1-\lambda^2)}{\lambda^2}$, this gives $\vert \eta\vert\leq \vert \lambda\vert$. Note that this assumption is trivially true when $\lambda<.85$.
		\item Finally assume $(1+\mu_k)^2\lambda^2-4\mu_k=0$. Then we must have $\eta = \frac{(1+\mu_k)\lambda}{2}$ giving
		\[\vert\eta\vert = \frac{(1+\mu_k)}{2}\vert \lambda\vert \leq \vert\lambda\vert. \]
	\end{itemize}
\end{proof}
This lemma tells us that, for small $k$, every eigenvalue of $T_k$ is bounded by its corresponding eigenvalue of $\frac{1}{m_i}L_i^*$. While the eigenspaces of $T_k$ vary with $k$, the next lemma provides a similar matrix which acts orthogonally on fixed two-dimensional spaces independent of $k$.
\begin{lem}\label{Tkshift}
	Define $\sqrt{\Delta}_m$ as the diagonal matrix with $\sqrt{m_j}$ as the $j^\text{th}$ diagonal element. For $0\leq i\leq d$, let $\vec{p}_i$ be the $i^\text{th}$ column of $P$ and define $\Omega_i = \left\{\left.\left[\begin{array}{c}
	a \vec{p}_i\\\hdashline[2pt/2pt]
	b\vec{p}_i
	\end{array}\right]\right\vert a,b\in\mathbb{C}\right\}$. Then for any $k>0$ and all $0\leq i\leq d$, $\left[\begin{array}{c;{2pt/2pt}c}
	\sqrt{\Delta}_m & 0\\\hdashline[2pt/2pt]
	0 & \sqrt{\Delta}_m
	\end{array}\right]T_k\left[\begin{array}{c;{2pt/2pt}c}
	\sqrt{\Delta}_m & 0\\\hdashline[2pt/2pt]
	0 & \sqrt{\Delta}_m
	\end{array}\right]^{-1}$ maps $\Omega_i\rightarrow\Omega_i$.
\end{lem}
\begin{proof}
	Recall from \label{kreinidentities} that the eigenvectors of $\frac{1}{m_i}L_i^*$ are given by the columns of $P$, denoted $\vec{p}_0,\vec{p}_1,\dots,\vec{p}_d$. Then Lemma \ref{Tkeig} shows that the eigenvectors of $T_k$ are the vectors $\left[\begin{array}{c}
	\eta \vec{p}_i\\\hdashline[2pt/2pt]
	\vec{p}_i
	\end{array}\right]$ for some constants $\eta$ which depend on the corresponding eigenvalues of $\frac{1}{m_i}L_i^*$. However, \ref{PQorthogonality} gives us
	\[\Delta_m P = Q^T\Delta_v;\qquad PQ = \frac{1}{\vert X\vert}I.\]
	Then $P^T\Delta_mP = P^TQ^T\Delta_v = \frac{1}{\vert X\vert}\Delta_v$.
\end{proof}

 To see this, let $\lambda$ be an eigenvalue of $\frac{1}{m_i}L_i^*$ with corresponding eigenvector $v$. Then for either solution of $\eta^2 =(1+\mu_k)\lambda\eta -\mu_k$, we may define a vector $w_\eta = \left[\begin{array}{c}
\eta v\\\hdashline[2pt/2pt]
v
\end{array}\right]$ and we have
\[T_kw_\eta = \left[\begin{array}{c}
(1+\mu_k)\frac{1}{m_i}L_i^*(\eta v) - \mu v\\\hdashline[2pt/2pt]
\eta v
\end{array}\right] = \left[\begin{array}{c}
\left((1+\mu_k)\lambda\eta - \mu_k\right) v\\\hdashline[2pt/2pt]
\eta v
\end{array}\right] = \eta w_\eta.\]
Thus every eigenpair of $\frac{1}{m_i}L_i^*$ gives us two distinct eigenpairs of $T_k$ as long as $(1+\mu_k)^2\lambda^2-4\mu_k\neq 0$.
\begin{lem}
	Let $(X,\mathcal{R})$ be an association scheme with minimal idempotents $E_0,E_1,\dots,E_d$. Let $P$ and $Q$ be the first and second eigenmatrices and denote the columns of $P$ as $\ones,\mathbf{p}_1,\dots,\mathbf{p}_d$. Fix $0\leq i\leq d$ and denote the $j^\text{th}$ entry of the $i^\text{th}$ column of $\frac{1}{m_i}Q$ as $q_j$. For $k\geq 2$ define $\mu_k$ and $T_k$ as in equation \eqref{tkdef}. Then the eigenpairs of $T_k$ are
	\[\scalebox{.8}{$\left\{\left(1,\ones\right),\left(\mu_k,\left[\begin{array}{c}
	\mu_k\ones\\\hdashline[2pt/2pt]
	\ones
	\end{array}\right]\right),\left(\eta_{q_1}^+,\left[\begin{array}{c}
	\eta_{q_1}^+\mathbf{p}_1\\\hdashline[2pt/2pt]
	\ones
	\end{array}\right]\right),\left(\eta_{q_1}^-,\left[\begin{array}{c}
	\eta_{q_1}^-\mathbf{p}_1\\\hdashline[2pt/2pt]
	\ones
	\end{array}\right]\right),\dots,\left(\eta_{q_d}^+,\left[\begin{array}{c}
	\eta_{q_d}^+\mathbf{p}_d\\\hdashline[2pt/2pt]
	\ones
	\end{array}\right]\right),\left(\eta_{q_d}^-,\left[\begin{array}{c}
	\eta_{q_d}^-\mathbf{p}_d\\\hdashline[2pt/2pt]
	\ones
	\end{array}\right]\right)\right\}$}\]
	where $\left\{\eta_x^+,\eta_x^-\right\}$ are the two solutions of $\eta^2-(1+\mu_k)x\eta+\mu_k = 0$. Further, for $1\leq j\leq d$, if $\mu_k\leq \frac{2(1-q_j^2)}{q_j^2}$ then $\max\left\{\vert \eta^-_{q_j}\vert,\vert \eta^+_{q_j}\vert\right\}\leq \max\left\{\mu_k,\vert q_j\vert\right\}$.
\end{lem}
\begin{proof}
	First note that the eigenpairs of $\frac{1}{m_i}L_i^*$ are exactly
	\[\scalebox{.8}{$\left\{\left(1,\ones\right),\left(\frac{Q_{1i}}{m_i},\mathbf{p_1}\right),\dots,\left(\frac{Q_{di}}{m_i},\mathbf{p_d}\right)\right\}$}.\]
	Now, for eigenpair $(\lambda,v)$ of $\frac{1}{m_i}L_i^*$, we have that
	\[T_k\left[\begin{array}{c}
	\eta v\\\hdashline[2pt/2pt]
	v
	\end{array}\right] = \left[\begin{array}{c}
	(1+\mu_k)\frac{1}{m_i}L_i^*(\eta v) - \mu v\\\hdashline[2pt/2pt]
	\eta v
	\end{array}\right] = \left[\begin{array}{c}
	\left((1+\mu_k)\lambda\eta - \mu_k\right) v\\\hdashline[2pt/2pt]
	\eta v
	\end{array}\right] =  \left[\begin{array}{c}
	\eta^2 v\\\hdashline[2pt/2pt]
	\eta v
	\end{array}\right]\]
	as long as $\eta$ is a solution to $\eta^2-(1+\mu_k)\lambda\eta+\mu_k = 0$. Next, note that if $\lambda=1$ then $\eta^2-(1+\mu_k)\lambda\eta+\mu_k = (\eta-1)(\eta-\mu_k)$, finishing the proof of the eigenpairs of $T_k$. 
\end{proof}
We did not cover the case of when $(1+\mu_k)^2\lambda^2-4\mu_k=0$, however this implies $\lambda^2\mu^2 +(2\lambda^2-4)\mu + \lambda^2 = 0$ giving,
\[\mu = \frac{4-2\lambda^2 \pm \sqrt{(2\lambda^2-4)^2-4\lambda^4}}{2\lambda^2} = \frac{2}{\lambda^2} - 1 \pm\frac{2\sqrt{1-\lambda^2}}{\lambda^2}.\]
Using our definition of $\mu$, we then have
\[\begin{aligned}(k-1)\lambda^2 &= (2-\lambda^2\pm2\sqrt{1-\lambda^2})(k+m-3)\\
k &= \frac{\lambda^2(m-2)}{2\left(\pm\sqrt{1-\lambda^2}-(1-\lambda^2)\right)}+m-1
\end{aligned}\]
Since $k$ must be an integer, we do not expect this to happen. This leads to the following lemma. We do need to be careful here, but I expect a proof of this to come relatively easily (or perhaps a statement that it doesnt matter).[TODO]\par
%%% Claims
\begin{lem}
	Let $P$ be the first eigenmatrix of an association scheme with multiplicities $1,m_1,m_2,\dots,m_d$. Define \[\Delta^{\frac{1}{2}} = \left[\begin{array}{cccc}
	1 & 0 & \dots & 0\\
	0 & \sqrt{m_1}  & \dots & 0\\
	\vdots & \vdots  & \ddots & \vdots\\
	0 & 0 & \dots & \sqrt{m_d}\\
	\end{array}\right].\]
	Then for distinct columns $p_i$ and $p_j$ of $P$,
	\[\left<\Delta^{\frac{1}{2}}p_i,\Delta^{\frac{1}{2}}p_j\right>= 0\]
\end{lem}
\begin{lem}
	Let 
	\[\delta = \left[\begin{array}{>{\centering\arraybackslash}p{3cm};{2pt/2pt}>{\centering\arraybackslash}p{3cm}}
	$\Delta^\frac{1}{2}$ & $0$\\\hdashline[2pt/2pt]
	$0$ & $\Delta^\frac{1}{2}$
	\end{array}\right].\]
	Then for eigenvectors $v_{\lambda}$, $v_{\eta}$ with $\lambda\neq \eta$ we have 
	\[\left<\delta v_\lambda,\delta v_\eta\right> = 0.\]
\end{lem}

\degbnd

\section{Cometric case}
In this section, we restrict to the case of cometric association schemes and determine the consequences of Theorem \ref{schoen-as}. Let $(X,\mathcal{R})$ be given and assume there exists a $Q$-polynomial ordering 



